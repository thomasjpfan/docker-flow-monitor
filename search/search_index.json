{
    "docs": [
        {
            "location": "/",
            "text": "Docker Flow Monitor\n\u00b6\n\n\n\n\n\n\n\n\n\n\nThe goal of the \nDocker Flow Monitor\n project is to provide an easy way to reconfigure Prometheus every time a new service is deployed, or when a service is updated. It does not try to \"reinvent the wheel\", but to leverage the existing leaders and combine them through an easy to use integration. It uses \nPrometheus\n as a metrics storage and query engine and adds custom logic that allows on-demand reconfiguration.\n\n\nPlease visit the \ntutorial\n for a brief introduction or \nConfiguring Docker Flow Monitor\n and \nUsage\n sections for more details.\n\n\nPlease join the #df-monitor Slack channel in \nDevOps20\n if you have any questions, suggestions, or problems.",
            "title": "Home"
        },
        {
            "location": "/#docker-flow-monitor",
            "text": "The goal of the  Docker Flow Monitor  project is to provide an easy way to reconfigure Prometheus every time a new service is deployed, or when a service is updated. It does not try to \"reinvent the wheel\", but to leverage the existing leaders and combine them through an easy to use integration. It uses  Prometheus  as a metrics storage and query engine and adds custom logic that allows on-demand reconfiguration.  Please visit the  tutorial  for a brief introduction or  Configuring Docker Flow Monitor  and  Usage  sections for more details.  Please join the #df-monitor Slack channel in  DevOps20  if you have any questions, suggestions, or problems.",
            "title": "Docker Flow Monitor"
        },
        {
            "location": "/tutorial/",
            "text": "Running Docker Flow Monitor\n\u00b6\n\n\nThe examples that follow assume that you have Docker Machine version v0.8+ that includes Docker Engine v1.12+.\n\n\n\n\nInfo\n\n\nIf you are a Windows user, please run all the examples from \nGit Bash\n (installed through \nDocker for Windows\n). Also, make sure that your Git client is configured to check out the code \nAS-IS\n. Otherwise, Windows might change carriage returns to the Windows format.\n\n\n\n\nSetting Up A Cluster\n\u00b6\n\n\n\n\nInfo\n\n\nFeel free to skip this section if you already have a Swarm cluster that can be used for this tutorial\n\n\n\n\nWe'll create a Swarm cluster consisting of three nodes created with Docker Machine.\n\n\ngit clone https://github.com/vfarcic/docker-flow-monitor.git\n\n\ncd\n docker-flow-monitor\n\n./scripts/dm-swarm.sh\n\n\neval\n \n$(\ndocker-machine env swarm-1\n)\n\n\n\n\n\nWe cloned the \nvfarcic/docker-flow-monitor\n repository. It contains all the scripts and stack files we'll use throughout this tutorial. Next, we executed the \ndm-swarm.sh\n script that created the cluster. Finally, we used the \neval\n command to tell our local Docker client to use the remote Docker engine \nswarm-1\n.\n\n\nNow that the cluster is up-and-running, we can deploy the \nDocker Flow Monitor\n stack.\n\n\nDeploying Docker Flow Monitor\n\u00b6\n\n\nWe'll deploy \nstacks/docker-flow-monitor-tutorial.yml\n stack that contains an example combination of parameters. The stack is as follows.\n\n\nThe stack contains three services; \nmonitor\n, \nalert-manager\n, and \nswarm-listener\n. We'll go through each separately.\n\n\nThe definition of the \nmonitor\n service is as follows.\n\n\n  monitor:\n    image: vfarcic/docker-flow-monitor\n    environment:\n      - LISTENER_ADDRESS=swarm-listener\n      - GLOBAL_SCRAPE_INTERVAL=10s\n      - ARG_ALERTMANAGER_URL=http://alert-manager:9093\n    networks:\n      - monitor\n    ports:\n      - 9090:9090\n\n\n\n\nThe environment variables show the first advantage of using \nDocker Flow Monitor\n instead directly Prometheus. All the configuration options and startup arguments can be specified as environment variables thus removing the need for configuration files and their persistence.\n\n\n\n\nInfo\n\n\nPlease visit \nConfiguring Docker Flow Monitor\n for more information about the available options.\n\n\n\n\nThe next in line is \nalert-manager\n service. The definition is as follows.\n\n\n  alert-manager:\n    image: vfarcic/alert-manager:slack\n    networks:\n      - monitor\n\n\n\n\nWe're using \nvfarcic/alert-manager:slack\n because it is already preconfigured to send notifications to \nDevOps20 Slack\n (channel #df-monitor-tests). Feel free to replace \nvfarcic/alert-manager:slack\n with your own image based on \nprom/alertmanager/\n.\n\n\nFinally, the last service in the stack is \nswarm-listener\n. The definition is as follows.\n\n\n  swarm-listener:\n    image: vfarcic/docker-flow-swarm-listener\n    networks:\n      - monitor\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    environment:\n      - DF_NOTIFY_CREATE_SERVICE_URL=http://monitor:8080/v1/docker-flow-monitor/reconfigure\n      - DF_NOTIFY_REMOVE_SERVICE_URL=http://monitor:8080/v1/docker-flow-monitor/remove\n    deploy:\n      placement:\n        constraints: [node.role == manager]\n\n\n\n\nThe \nswarm-listener\n service will listen to Swarm events and notify \nmonitor\n whenever a service is created, updated, or removed.\n\n\n\n\nInfo\n\n\nPlease visit \nDocker Flow Swarm Listener documentation\n for more information about the project.\n\n\n\n\nLet's deploy the \nmonitor\n stack\n\n\ndocker network create -d overlay monitor\n\ndocker stack deploy \n\\\n\n    -c stacks/docker-flow-monitor-tutorial.yml \n\\\n\n    monitor\n\n\n\n\nPlease wait until all the services are running. You can check their statuses by executing \ndocker stack ps monitor\n command.\n\n\nNow we can open \nPrometheus\n from a browser.\n\n\n\n\nIf you're a Windows user, Git Bash might not be able to use the \nopen\n command. If that's the case, replace the \nopen\n command with \necho\n. As a result, you'll get the full address that should be opened directly in your browser of choice.\n\n\n\n\nopen \n\"http://\n$(\ndocker-machine ip swarm-1\n)\n:9090\"\n\n\n\n\n\nIf you navigate to the \nStatus > Command-Line Flags\n screen, you'll notice that \nalertmanager.url\n entry is already configured through the environment variable \nARG_ALERTMANAGER_URL\n. Similarly, the \nStatus > Configuration\n screen also has the configuration created through the environment variable \nGLOBAL_SCRAPE_INTERVAL\n.\n\n\nNow we can start collecting metrics.\n\n\nCollecting Metrics And Defining Alerts\n\u00b6\n\n\nPrometheus is a pull system. It scrapes exporters and stores metrics in its internal database.\n\n\nLet us deploy a few exporters.\n\n\nWe'll deploy exporter stack defined in the \nstacks/exporters-tutorial.yml\n. It contains two services; \ncadvisor\n and \nnode-exporter\n.\n\n\nThe definition of the \ncadvisor\n service is as follows.\n\n\n  cadvisor:\n    image: google/cadvisor\n    ...\n    deploy:\n      mode: global\n      labels:\n        - com.df.notify=true\n        - com.df.scrapePort=8080\n\n\n\n\nService labels are what make this service special. \ncom.df.notify\n tells \nswarm-listener\n that it should notify \nmonitor\n when this service is created, updated, or removed. The \ncom.df.scrapePort\n label specifies that Prometheus should scrape data from this service running on port \n8080\n.\n\n\n\n\nInfo\n\n\nPlease visit \nUsage documentation\n for more information about the available options.\n\n\n\n\nThe second service (\nnode-exporter\n) defines more than scraping port. The definition is as follows.\n\n\n  node-exporter:\n    image: basi/node-exporter\n    ...\n    deploy:\n      mode: global\n      labels:\n        - com.df.notify=true\n        - com.df.scrapePort=9100\n        - com.df.alertName.1=memload\n        - com.df.alertIf.1=(sum by (instance) (node_memory_MemTotal) - sum by (instance) (node_memory_MemFree + node_memory_Buffers + node_memory_Cached)) / sum by (instance) (node_memory_MemTotal) > 0.8\n        - com.df.alertName.2=diskload\n        - com.df.alertIf.2=@node_fs_limit:0.8\n    ...\n\n\n\n\nThis time, we added a few additional labels. \ncom.df.alertName.1\n will tell Prometheus that it should create an alert called \nmemload\n. The name of the alert is accompanied with the condition specified as \ncom.df.alertIf.1\n. Multiple alerts can be defined by adding labels with incremental indexes. As the second alert, we used \ncom.df.alertName.2=diskload\n to defined the name and \ncom.df.alertIf.2=@node_fs_limit:0.8\n to define the condition. This time, we use one of the shortcuts instead writing the full syntax.\n\n\nLet's deploy the \nexporter\n stack.\n\n\ndocker stack deploy \n\\\n\n    -c stacks/exporters-tutorial.yml \n\\\n\n    exporter\n\n\n\n\nPlease wait until the service in the stack are up-and-running. You can check their status by executing \ndocker stack ps exporter\n command.\n\n\nIf you go back to Prometheus and navigate to the \nStatus > Configuration\n screen, you'll notice that exporters are automatically added as well as the path to the rules file that contains alerts. To be on the safe side, please open the \nStatus > Targets\n screen. It should contain three endpoints for each of the two targets we created.\n\n\nThe two alerts were created as well. You can see their status by navigating to the \nAlerts\n screen.\n\n\nWe'll deploy one more stack. This time, we'll create a few demo services as a way to demonstrate that alerts creation is not limited to exporters but that it can be applied to any Swarm service.\n\n\nThe stack we'll deploy is as follows.\n\n\nversion: '3'\n\nservices:\n\n  main:\n    image: vfarcic/go-demo\n    environment:\n      - DB=db\n    ports:\n      - 8080:8080\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        delay: 10s\n      labels:\n        - com.df.notify=true\n        - com.df.distribute=true\n        - com.df.alertName=memlimit\n        - com.df.alertIf=@service_mem_limit:0.8\n        - com.df.alertFor=30s\n      resources:\n        reservations:\n          memory: 5M\n        limits:\n          memory: 10M\n\n  db:\n    image: mongo\n\n\n\n\nIn this context, the details of the services are not important. What matters is that we defined that the service should create an alert named \nmemlimit\n and that the condition is defined as the \n@service_mem_limit:0.8\n shortcut. It will create an alert that will be fired if memory usage is over 80% of the memory limit which is set to 10MB. Additionally, we also set the \nalertFor\n label tells Prometheus to fire the alert only if the condition persists for more than 30 seconds.\n\n\nLet's deploy the \ngo-demo\n stack.\n\n\ndocker stack deploy \n\\\n\n    -c stacks/go-demo-tutorial.yml \n\\\n\n    go-demo\n\n\n\n\nIf you go back to the alerts screen, you'll see that a new entry is added.\n\n\nIt is up to you to configure \nAlert Manager\n so that those alerts are propagated accordingly (e.g. to Slack, Jenkins, email, and so on).\n\n\nWhat Now?\n\u00b6\n\n\nThat was a very brief introduction to \nDocker Flow Monitor\n. Please consult the documentation for any additional information you might need. Feel free to open \nan issue\n if you require additional info, if you find a bug, or if you have a feature request.\n\n\nBefore you go, please remove the cluster we created and free those resources for something else.\n\n\ndocker-machine rm -f swarm-1 swarm-2 swarm-3",
            "title": "Running Docker Flow Monitor"
        },
        {
            "location": "/tutorial/#running-docker-flow-monitor",
            "text": "The examples that follow assume that you have Docker Machine version v0.8+ that includes Docker Engine v1.12+.   Info  If you are a Windows user, please run all the examples from  Git Bash  (installed through  Docker for Windows ). Also, make sure that your Git client is configured to check out the code  AS-IS . Otherwise, Windows might change carriage returns to the Windows format.",
            "title": "Running Docker Flow Monitor"
        },
        {
            "location": "/tutorial/#setting-up-a-cluster",
            "text": "Info  Feel free to skip this section if you already have a Swarm cluster that can be used for this tutorial   We'll create a Swarm cluster consisting of three nodes created with Docker Machine.  git clone https://github.com/vfarcic/docker-flow-monitor.git cd  docker-flow-monitor\n\n./scripts/dm-swarm.sh eval   $( docker-machine env swarm-1 )   We cloned the  vfarcic/docker-flow-monitor  repository. It contains all the scripts and stack files we'll use throughout this tutorial. Next, we executed the  dm-swarm.sh  script that created the cluster. Finally, we used the  eval  command to tell our local Docker client to use the remote Docker engine  swarm-1 .  Now that the cluster is up-and-running, we can deploy the  Docker Flow Monitor  stack.",
            "title": "Setting Up A Cluster"
        },
        {
            "location": "/tutorial/#deploying-docker-flow-monitor",
            "text": "We'll deploy  stacks/docker-flow-monitor-tutorial.yml  stack that contains an example combination of parameters. The stack is as follows.  The stack contains three services;  monitor ,  alert-manager , and  swarm-listener . We'll go through each separately.  The definition of the  monitor  service is as follows.    monitor:\n    image: vfarcic/docker-flow-monitor\n    environment:\n      - LISTENER_ADDRESS=swarm-listener\n      - GLOBAL_SCRAPE_INTERVAL=10s\n      - ARG_ALERTMANAGER_URL=http://alert-manager:9093\n    networks:\n      - monitor\n    ports:\n      - 9090:9090  The environment variables show the first advantage of using  Docker Flow Monitor  instead directly Prometheus. All the configuration options and startup arguments can be specified as environment variables thus removing the need for configuration files and their persistence.   Info  Please visit  Configuring Docker Flow Monitor  for more information about the available options.   The next in line is  alert-manager  service. The definition is as follows.    alert-manager:\n    image: vfarcic/alert-manager:slack\n    networks:\n      - monitor  We're using  vfarcic/alert-manager:slack  because it is already preconfigured to send notifications to  DevOps20 Slack  (channel #df-monitor-tests). Feel free to replace  vfarcic/alert-manager:slack  with your own image based on  prom/alertmanager/ .  Finally, the last service in the stack is  swarm-listener . The definition is as follows.    swarm-listener:\n    image: vfarcic/docker-flow-swarm-listener\n    networks:\n      - monitor\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    environment:\n      - DF_NOTIFY_CREATE_SERVICE_URL=http://monitor:8080/v1/docker-flow-monitor/reconfigure\n      - DF_NOTIFY_REMOVE_SERVICE_URL=http://monitor:8080/v1/docker-flow-monitor/remove\n    deploy:\n      placement:\n        constraints: [node.role == manager]  The  swarm-listener  service will listen to Swarm events and notify  monitor  whenever a service is created, updated, or removed.   Info  Please visit  Docker Flow Swarm Listener documentation  for more information about the project.   Let's deploy the  monitor  stack  docker network create -d overlay monitor\n\ndocker stack deploy  \\ \n    -c stacks/docker-flow-monitor-tutorial.yml  \\ \n    monitor  Please wait until all the services are running. You can check their statuses by executing  docker stack ps monitor  command.  Now we can open  Prometheus  from a browser.   If you're a Windows user, Git Bash might not be able to use the  open  command. If that's the case, replace the  open  command with  echo . As a result, you'll get the full address that should be opened directly in your browser of choice.   open  \"http:// $( docker-machine ip swarm-1 ) :9090\"   If you navigate to the  Status > Command-Line Flags  screen, you'll notice that  alertmanager.url  entry is already configured through the environment variable  ARG_ALERTMANAGER_URL . Similarly, the  Status > Configuration  screen also has the configuration created through the environment variable  GLOBAL_SCRAPE_INTERVAL .  Now we can start collecting metrics.",
            "title": "Deploying Docker Flow Monitor"
        },
        {
            "location": "/tutorial/#collecting-metrics-and-defining-alerts",
            "text": "Prometheus is a pull system. It scrapes exporters and stores metrics in its internal database.  Let us deploy a few exporters.  We'll deploy exporter stack defined in the  stacks/exporters-tutorial.yml . It contains two services;  cadvisor  and  node-exporter .  The definition of the  cadvisor  service is as follows.    cadvisor:\n    image: google/cadvisor\n    ...\n    deploy:\n      mode: global\n      labels:\n        - com.df.notify=true\n        - com.df.scrapePort=8080  Service labels are what make this service special.  com.df.notify  tells  swarm-listener  that it should notify  monitor  when this service is created, updated, or removed. The  com.df.scrapePort  label specifies that Prometheus should scrape data from this service running on port  8080 .   Info  Please visit  Usage documentation  for more information about the available options.   The second service ( node-exporter ) defines more than scraping port. The definition is as follows.    node-exporter:\n    image: basi/node-exporter\n    ...\n    deploy:\n      mode: global\n      labels:\n        - com.df.notify=true\n        - com.df.scrapePort=9100\n        - com.df.alertName.1=memload\n        - com.df.alertIf.1=(sum by (instance) (node_memory_MemTotal) - sum by (instance) (node_memory_MemFree + node_memory_Buffers + node_memory_Cached)) / sum by (instance) (node_memory_MemTotal) > 0.8\n        - com.df.alertName.2=diskload\n        - com.df.alertIf.2=@node_fs_limit:0.8\n    ...  This time, we added a few additional labels.  com.df.alertName.1  will tell Prometheus that it should create an alert called  memload . The name of the alert is accompanied with the condition specified as  com.df.alertIf.1 . Multiple alerts can be defined by adding labels with incremental indexes. As the second alert, we used  com.df.alertName.2=diskload  to defined the name and  com.df.alertIf.2=@node_fs_limit:0.8  to define the condition. This time, we use one of the shortcuts instead writing the full syntax.  Let's deploy the  exporter  stack.  docker stack deploy  \\ \n    -c stacks/exporters-tutorial.yml  \\ \n    exporter  Please wait until the service in the stack are up-and-running. You can check their status by executing  docker stack ps exporter  command.  If you go back to Prometheus and navigate to the  Status > Configuration  screen, you'll notice that exporters are automatically added as well as the path to the rules file that contains alerts. To be on the safe side, please open the  Status > Targets  screen. It should contain three endpoints for each of the two targets we created.  The two alerts were created as well. You can see their status by navigating to the  Alerts  screen.  We'll deploy one more stack. This time, we'll create a few demo services as a way to demonstrate that alerts creation is not limited to exporters but that it can be applied to any Swarm service.  The stack we'll deploy is as follows.  version: '3'\n\nservices:\n\n  main:\n    image: vfarcic/go-demo\n    environment:\n      - DB=db\n    ports:\n      - 8080:8080\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        delay: 10s\n      labels:\n        - com.df.notify=true\n        - com.df.distribute=true\n        - com.df.alertName=memlimit\n        - com.df.alertIf=@service_mem_limit:0.8\n        - com.df.alertFor=30s\n      resources:\n        reservations:\n          memory: 5M\n        limits:\n          memory: 10M\n\n  db:\n    image: mongo  In this context, the details of the services are not important. What matters is that we defined that the service should create an alert named  memlimit  and that the condition is defined as the  @service_mem_limit:0.8  shortcut. It will create an alert that will be fired if memory usage is over 80% of the memory limit which is set to 10MB. Additionally, we also set the  alertFor  label tells Prometheus to fire the alert only if the condition persists for more than 30 seconds.  Let's deploy the  go-demo  stack.  docker stack deploy  \\ \n    -c stacks/go-demo-tutorial.yml  \\ \n    go-demo  If you go back to the alerts screen, you'll see that a new entry is added.  It is up to you to configure  Alert Manager  so that those alerts are propagated accordingly (e.g. to Slack, Jenkins, email, and so on).",
            "title": "Collecting Metrics And Defining Alerts"
        },
        {
            "location": "/tutorial/#what-now",
            "text": "That was a very brief introduction to  Docker Flow Monitor . Please consult the documentation for any additional information you might need. Feel free to open  an issue  if you require additional info, if you find a bug, or if you have a feature request.  Before you go, please remove the cluster we created and free those resources for something else.  docker-machine rm -f swarm-1 swarm-2 swarm-3",
            "title": "What Now?"
        },
        {
            "location": "/auto-scaling/",
            "text": "Auto-Scaling Docker Swarm Services Using Instrumented Metrics\n\u00b6\n\n\nDocker Swarm provides a solid mechanism that, among other things, makes sure that the specified number of replicas of a service is (almost) always running inside a cluster. It is performing self-healing out-of-the-box. However, that is often not enough. We need the system to adapt to changed conditions. We'll call this process self-adaptation.\n\n\nIn this tutorial, we'll go through one possible setup that allows self-adaptation of services based on their response time. That does not mean that response time metrics are the only ones we should use. Quite the contrary. However, we need to limit the scope of this tutorial and response times are probably one of the most commonly used metrics when applying self-adaptation.\n\n\nThe tools we'll use to setup a self-adaptive system are as follows.\n\n\n\n\nPrometheus\n: Scrapes metrics and fires alerts when certain thresholds are reached.\n\n\nDocker Flow Monitor\n: It extends Prometheus with capability to auto-configure itself.\n\n\nAlertmanager\n: Receives alerts from Prometheus and forwards them to some other service depending on matching routes.\n\n\nJenkins\n: Executes scheduled or triggered jobs. We'll use it as the engine that will scale a service.\n\n\nDocker Flow Proxy\n: It extends HAProxy with capability to auto-configure itself.\n\n\nDocker Flow Swarm Listener\n: Listens to Swarm events and sends notifications when a service is created or updated. We'll use it to send notifications to \nDocker Flow Monitor\n and \nDocker Flow Proxy\n.\n\n\ngo-demo\n: A demo service.\n\n\n\n\n\n\n\nThe examples that follow assume that you have Docker Machine version v0.8+ that includes Docker Engine v1.12+.\n\n\n\n\nInfo\n\n\nIf you are a Windows user, please run all the examples from \nGit Bash\n (installed through \nDocker for Windows\n). Also, make sure that your Git client is configured to check out the code \nAS-IS\n. Otherwise, Windows might change carriage returns to the Windows format.\n\n\n\n\nSetting Up A Cluster\n\u00b6\n\n\n\n\nInfo\n\n\nFeel free to skip this section if you already have a Swarm cluster that can be used for this tutorial\n\n\n\n\nWe'll create a Swarm cluster consisting of three nodes created with Docker Machine.\n\n\ngit clone https://github.com/vfarcic/docker-flow-monitor.git\n\n\ncd\n docker-flow-monitor\n\n./scripts/dm-swarm.sh\n\n\neval\n \n$(\ndocker-machine env swarm-1\n)\n\n\n\n\n\nWe cloned the \nvfarcic/docker-flow-monitor\n repository. It contains all the scripts and stack files we'll use throughout this tutorial. Next, we executed the \ndm-swarm.sh\n script that created the cluster. Finally, we used the \neval\n command to tell our local Docker client to use the remote Docker engine \nswarm-1\n.\n\n\nDeploying Docker Flow Proxy (DFP) and Docker Flow Swarm Listener (DFSL)\n\u00b6\n\n\nProxy is not strictly necessary for this tutorial. We're using it only as a convenient way to get a single access point to the cluster instead opening a different port for each publicly accessible service.\n\n\ndocker network create -d overlay proxy\n\ndocker stack deploy \n\\\n\n    -c stacks/docker-flow-proxy-mem.yml \n\\\n\n    proxy\n\n\n\n\nThe stack deployed two services; \nproxy\n and \nswarm-listener\n. From now on, the proxy will be notified whenever a service is deployed or updated as long as it has the \ncom.df.notify\n label set to \ntrue\n. Please consult \ndocker-flow-proxy-mem.yml\n for the full definition of the stack. For information about those two projects, please visit \nproxy.dockerflow.com\n and \nswarmlistener.dockerflow.com\n.\n\n\nDeploying Docker Flow Monitor and Alertmanager\n\u00b6\n\n\nThe next stack defines \nDocker Flow Monitor\n and \nAlertmanager\n. Before we deploy the stack, we should create the \nmonitor\n network that will allow Prometheus to scrape metrircs from exporters and instrumented services.\n\n\ndocker network create -d overlay monitor\n\n\n\n\nNext we'll create \nAlertmanager\n configuration as a Docker secret. That way we won't need to create a new image with configuration or mount a volume.\n\n\necho\n \n\"route:\n\n\n  group_by: [service,scale]\n\n\n  repeat_interval: 5m\n\n\n  group_interval: 5m\n\n\n  receiver: 'slack'\n\n\n  routes:\n\n\n  - match:\n\n\n      service: 'go-demo_main'\n\n\n      scale: 'up'\n\n\n    receiver: 'jenkins-go-demo_main-up'\n\n\n  - match:\n\n\n      service: 'go-demo_main'\n\n\n      scale: 'down'\n\n\n    receiver: 'jenkins-go-demo_main-down'\n\n\n\nreceivers:\n\n\n  - name: 'slack'\n\n\n    slack_configs:\n\n\n      - send_resolved: true\n\n\n        title: '[{{ .Status | toUpper }}] {{ .GroupLabels.service }} service is in danger!'\n\n\n        title_link: 'http://\n$(\ndocker-machine ip swarm-1\n)\n/monitor/alerts'\n\n\n        text: '{{ .CommonAnnotations.summary}}'\n\n\n        api_url: 'https://hooks.slack.com/services/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'\n\n\n  - name: 'jenkins-go-demo_main-up'\n\n\n    webhook_configs:\n\n\n      - send_resolved: false\n\n\n        url: 'http://\n$(\ndocker-machine ip swarm-1\n)\n/jenkins/job/service-scale/buildWithParameters?token=DevOps22&service=go-demo_main&scale=1'\n\n\n  - name: 'jenkins-go-demo_main-down'\n\n\n    webhook_configs:\n\n\n      - send_resolved: false\n\n\n        url: 'http://\n$(\ndocker-machine ip swarm-1\n)\n/jenkins/job/service-scale/buildWithParameters?token=DevOps22&service=go-demo_main&scale=-1'\n\n\n\"\n \n|\n docker secret create alert_manager_config -\n\n\n\n\nThe configuration groups routes by \nservice\n and \nscale\n labels. The \nrepeat_interval\n and \ngroup_interval\n are both set to five minutes. In a production cluster, \nrepeat_interval\n should be set to a much larger value (e.g. \n1h\n). We set it up to five minutes so that we can demonstrate different features of the system faster. Otherwise, we'd need to wait for over an hour to see different alerts in action.\n\n\nThe default receiver is \nslack\n. As the result, any alert that does not match one of the \nroutes\n will be sent to Slack.\n\n\nThe \nroutes\n section defines two \nmatch\n entries. If the alert label \nservice\n is set to \ngo-demo_main\n and the label \nscale\n is \nup\n, the receiver will be \njenkins-go-demo_main-up\n. Similarly, when the same service is associated with an alert but the \nscale\n label is set to \ndown\n, the receiver will be \njenkins-go-demo_main-down\n.\n\n\nThere are three receivers. The \nslack\n receiver will send notifications to Slack. As stated before, it's used only for alerts that do not \nmatch\n one of the \nroutes\n. Both \njenkins-go-demo_main-up\n and \njenkins-go-demo_main-down\n are sending a \nPOST\n request to Jenkins job \nservice-scale\n. The only difference between the two is in the \nscale\n parameter. One will set it to \n1\n indicating that the \ngo-demo_main\n service should be up-scaled by one and the other will set it to \n-1\n indicating that the service should de de-scaled by 1.\n\n\nPlease consult \nconfiguration\n section of Alertmanager documentation for more information about the options we used.\n\n\nNow we can deploy the \nmonitor\n stack.\n\n\nDOMAIN\n=\n$(\ndocker-machine ip swarm-1\n)\n \n\\\n\n    docker stack deploy \n\\\n\n    -c stacks/docker-flow-monitor-slack.yml \n\\\n\n    monitor\n\n\n\n\nThe full definition of the stack that we just deployed can be found in \ndocker-flow-monitor-slack.yml\n. We'll comment only on a few interesting parts. The definition, limited to relevant parts, is as follows.\n\n\n...\n  monitor:\n    image: vfarcic/docker-flow-monitor\n    environment:\n      - LISTENER_ADDRESS=swarm-listener\n      - GLOBAL_SCRAPE_INTERVAL=${SCRAPE_INTERVAL:-10s}\n      - ARG_WEB_ROUTE-PREFIX=/monitor\n      - ARG_WEB_EXTERNAL-URL=http://${DOMAIN:-localhost}/monitor\n      - ARG_ALERTMANAGER_URL=http://alert-manager:9093\n    ...\n    deploy:\n      labels:\n        ...\n        - com.df.servicePath=/monitor\n        - com.df.serviceDomain=${DOMAIN:-localhost}\n        - com.df.port=9090\n      ...\n\n  alert-manager:\n    image: prom/alertmanager\n    networks:\n      - monitor\n    secrets:\n      - alert_manager_config\n    command: --config.file=/run/secrets/alert_manager_config --storage.path=/alertmanager\n\n  swarm-listener:\n    image: vfarcic/docker-flow-swarm-listener\n    ...\n    environment:\n      - DF_NOTIFY_CREATE_SERVICE_URL=http://monitor:8080/v1/docker-flow-monitor/reconfigure\n      - DF_NOTIFY_REMOVE_SERVICE_URL=http://monitor:8080/v1/docker-flow-monitor/remove\n    ...\n\n\n\n\nInside the \nmonitor\n service, we used environment variables to provide initial Prometheus configuration. The labels will be used by \nswarm\n listener to notify the proxy about monitor's path, domain, and port.\n\n\nThe \nalert-manager\n service uses \nalert_manager_config\n secret as Alertmanager configuration file.\n\n\nThe \nswarm-listener\n service has \nmonitor\n running on port \n8080\n as URL where notifications should be sent.\n\n\nPlease consult \nDocker Flow Monitor documentation\n for more information. If you haven't used it before, the \nRunning Docker Flow Monitor tutorial\n might be a good starting point.\n\n\nLet us confirm that the \nmonitor\n stack is up and running.\n\n\ndocker stack ps monitor\n\n\n\n\nPlease wait a few moments if some of the replicas do not yet have the status set to \nrunning\n.\n\n\nNow that the \nmonitor\n stack is up and running, we should proceed with deployment of Jenkins and its agent.\n\n\nDeploying Jenkins\n\u00b6\n\n\nThe Jenkins image we'll run already has all the plugins baked in. The administrative user and password will be retrieved from Docker secrets. A job that will scale and de-scale services is also defined inside the image. With those in place, we'll be able to skip manual setup.\n\n\necho\n \n\"admin\"\n \n|\n \n\\\n\n    docker secret create jenkins-user -\n\n\necho\n \n\"admin\"\n \n|\n \n\\\n\n    docker secret create jenkins-pass -\n\n\nexport\n \nSLACK_IP\n=\n$(\nping \n\\\n\n    -c \n1\n devops20.slack.com \n\\\n\n    \n|\n awk -F\n'[()]'\n \n'/PING/{print $2}'\n)\n\n\ndocker stack deploy \n\\\n\n    -c stacks/jenkins-scale.yml jenkins\n\n\n\n\nWe created two secrets that define administrative username and password. The environment variable \nSLACK_IP\n might not be necessary. It's there just in case Docker Machine cannot resolve Slack. Finally, the last command deployed the \njenkins\n stack.\n\n\nI won't go into much detailed about the \njenkins\n stack. If you're interested in the subject, you might want to read \nAutomating Jenkins Docker Setup\n article or watch the \nJenkins Master As a Docker Service Running Inside a Docker for AWS Cluster\n video. The only thing that truly matters is the \nservice-scale\n job that we'll explore soon.\n\n\nBefore we proceed, please confirm that all the replicas of the stack are running.\n\n\ndocker stack ps jenkins\n\n\n\n\nOnce all the replicas of the stack are in the \nrunning\n state, we can open the \nservice-scale\n job and take a quick look at its definition.\n\n\n\n\nIf you're a Windows user, Git Bash might not be able to use the \nopen\n command. If that's the case, replace the \nopen\n command with \necho\n. As a result, you'll get the full address that should be opened directly in your browser of choice.\n\n\n\n\nopen \n\"http://\n$(\ndocker-machine ip swarm-1\n)\n/jenkins/job/service-scale/configure\"\n\n\n\n\n\nYou will be presented with a login screen. Please use \nadmin\n as both username and password to authenticate.\n\n\nPlease click the \nPipeline\n tab once you get inside the \nservice-scale\n configuration screen.\n\n\nThe first half of the job is relatively straightforward. The job should be executed inside a \nprod\n agent (short for production). It defines two parameters. One holds the name of the service that should be scaled. The other expected a number of replicas that should be added or removed. If the value is positive, the service will be up-scaled. A negative value means that it should de-scale.\n\n\nThe job defines only one stage called \nScale\n. Inside it is a single step defined inside a \nscript\n. It executes \ndocker service inspect\n command and retrieves the current number of replicas. It also retrieves \nscaleMin\n and \nscaleMax\n labels to discover the limits that should be applied to scaling. Without them, we would run a risk of scaling to infinity or de-scaling to zero replicas.\n\n\nThe desired number of replicas (\nnewReplicas\n) is obtained by subtracting the current number of replicas with the \nscale\n parameter.\n\n\nOnce all the variables are set, it evaluates whether scaling would hit thresholds defined with \nscaleMin\n and \nscaleMax\n. If it would, it throws an error which, later on in the \npost\n section, results in a message to Slack. If neither thresholds would be reached, a simple \ndocker service scale\n command is executed.\n\n\nSince Jenkins pipeline is defined using \nDeclarative syntax\n, the first execution needs to be manual so that it is correctly processed and the parameters are created.\n\n\nPlease open the \nservice-scale\n activity screen.\n\n\nopen \n\"http://\n$(\ndocker-machine ip swarm-1\n)\n/jenkins/blue/organizations/jenkins/service-scale/activity\"\n\n\n\n\n\nNow click the \nRun\n button. A few moments later, you'll see that the build failed. Don't panic. That is expected. It's a workaround to bypass a bug and create the proper job definition with all the parameters. It will not fail again for the same reason.\n\n\nDeploying Instrumented Service\n\u00b6\n\n\nThe \ngo-demo\n service is already instrumented. Among others, it request generates \nresp_time\n metrics with response time, service name, response code, and path labels.\n\n\nWe won't go into details of how the service was instrumented but only comment on a few snippets. The code of the whole service is in a single file \nmain.go\n. Do not be afraid! We're using Go only to demonstrate how instrumentation works. You can implement similar principles in almost any programming language. Hopefully, you should have no problem understanding the logic behind it even if Go is not your programming language of choice.\n\n\nAs an example, every request starting with the \n/demo/hello\n path is sent to the \nHelloServer\n function. The relevant part of the function is as follows.\n\n\nfunc\n \nHelloServer\n(\nw\n \nhttp\n.\nResponseWriter\n,\n \nreq\n \n*\nhttp\n.\nRequest\n)\n \n{\n\n    \nstart\n \n:=\n \ntime\n.\nNow\n()\n\n    \ndefer\n \nfunc\n()\n \n{\n \nrecordMetrics\n(\nstart\n,\n \nreq\n,\n \nhttp\n.\nStatusOK\n)\n \n}()\n\n    \n...\n\n\n}\n\n\n\n\n\nWe record the time (\nstart\n) and defer the invocation of the \nrecordMetric\n function. In Go, \ndefer\n means that the function will be executed at the end of the context it is defined in. Like that, we guarantee that the \nrecordMetrics\n will be invoked after the request is processed and the response is sent back to the client.\n\n\nThe \nrecordMetric\n function records (observes) the duration of the response by calculating the difference between the current and the start time. That observation is done with a few labels that will, later on, allow us to query metrics from Prometheus and define alerts.\n\n\nfunc\n \nrecordMetrics\n(\nstart\n \ntime\n.\nTime\n,\n \nreq\n \n*\nhttp\n.\nRequest\n,\n \ncode\n \nint\n)\n \n{\n\n    \nduration\n \n:=\n \ntime\n.\nSince\n(\nstart\n)\n\n    \nhistogram\n.\nWith\n(\n\n        \nprometheus\n.\nLabels\n{\n\n            \n\"service\"\n:\n \nserviceName\n,\n\n            \n\"code\"\n:\n \nfmt\n.\nSprintf\n(\n\"%d\"\n,\n \ncode\n),\n\n            \n\"method\"\n:\n \nreq\n.\nMethod\n,\n\n            \n\"path\"\n:\n \nreq\n.\nURL\n.\nPath\n,\n\n        \n},\n\n    \n).\nObserve\n(\nduration\n.\nSeconds\n())\n\n\n}\n\n\n\n\n\nFor more information, please consult \ninstrumentation\n or \nclient libraries\n pages of Prometheus documentation.\n\n\nNow we can deploy the last stack. It will be the service we're hoping to scale based on response time metrics.\n\n\ndocker stack deploy \n\\\n\n    -c stacks/go-demo-instrument-alert-short.yml \n\\\n\n    go-demo\n\n\n\n\nPlease visit \ngo-demo-instrument-alert-short.yml\n for the full stack definition. We'll comment only on service labels since the rest should be pretty straightforward.\n\n\n  main:\n    ...\n    deploy:\n      ...\n      labels:\n        - com.df.notify=true\n        - com.df.distribute=true\n        - com.df.servicePath=/demo\n        - com.df.port=8080\n        - com.df.scaleMin=2\n        - com.df.scaleMax=4\n        - com.df.scrapePort=8080\n        - com.df.alertName.1=mem_limit\n        - com.df.alertIf.1=@service_mem_limit:0.8\n        - com.df.alertFor.1=5m\n        - com.df.alertName.2=resp_time_above\n        - com.df.alertIf.2=@resp_time_above:0.1,5m,0.99\n        - com.df.alertName.3=resp_time_below\n        - com.df.alertIf.3=@resp_time_below:0.025,5m,0.75\n      ...\n\n\n\n\nThe \nservicePath\n and \nport\n label will be used by \nDocker Flow Proxy\n to configure itself and start forwarding requests coming to \n/demo\n to the \ngo-demo\n service.\n\n\nYou already saw the usage of \nscaleMin\n and \nscaleMax\n labels. Jenkins uses them to decide whether the service should be scale or the number of replicas already reached the limits.\n\n\nThe \nalertName\n, \nalertIf\n, and \nalertFor\n labels are the key to scaling. The define Prometheus alerts. The first one (\nmemlimit\n) is already described in the \nRunning Docker Flow Monitor tutorial\n so will skip it. The second (\nresp_time_above\n) defines alert that will be fired if the rate of response times of the \n0.1\n seconds bucket (100 milliseconds or faster) is above 99% (\n0.99\n) for over five minutes (\n5m\n). Similarly, the \nresp_time_below\n alert will fire if the rate of response times of the \n0.025\n seconds bucket (25 milliseconds or faster) is below 75% (\n0.75\n) for over five minutes (\n5m\n). In all the cases, we're using \nAlertIf Parameter Shortcuts\n that will be expanded into full Prometheus expressions.\n\n\nLet's take a look at Prometheus alert screen.\n\n\nopen \n\"http://\n$(\ndocker-machine ip swarm-1\n)\n/monitor/alerts\"\n\n\n\n\n\nYou should see three alerts that correspond to the three labels define in the \nmain\n service of the \ngo-demo\n stack. \nDocker Flow Swarm Listener\n detected the new service and sent those labels to \nDocker Flow Monitor\n which, in turn, converted them info Prometheus configuration.\n\n\nIf you expand the \ngodemo_main_resp_time_above\n alert, you'll see that DFM translated the service labels into the alert definition that follows.\n\n\nalert: godemo_main_resptimeabove\nexpr: sum(rate(http_server_resp_time_bucket{job=\"go-demo_main\",le=\"0.1\"}[5m]))\n  / sum(rate(http_server_resp_time_count{job=\"go-demo_main\"}[5m])) < 0.99\nlabels:\n  receiver: system\n  scale: up\n  service: go-demo_main\n  type: service\nannotations:\n  summary: Response time of the service go-demo_main is above 0.1\n\n\n\n\nSimilarly, the \ngodemo_main_resp_time_below\n alert is defined as follows.\n\n\nalert: godemo_main_resptimebelow\nexpr: sum(rate(http_server_resp_time_bucket{job=\"go-demo_main\",le=\"0.025\"}[5m]))\n  / sum(rate(http_server_resp_time_count{job=\"go-demo_main\"}[5m])) > 0.75\nlabels:\n  receiver: system\n  scale: down\n  service: go-demo_main\n  type: service\nannotations:\n  summary: Response time of the service go-demo_main is below 0.025\n\n\n\n\nLet's confirm that the \ngo-demo\n stack is up-and-running.\n\n\ndocker stack ps -f desired-state\n=\nrunning go-demo\n\n\n\n\nYou should see three replicas of the \ngo-demo_main\n and one replica of the \ngo-demo_db\n service. If that's not the case, please wait a while longer and repeat the \ndocker stack ps\n command.\n\n\nWe should confirm that all the targets of the service are indeed registered.\n\n\nopen \n\"http://\n$(\ndocker-machine ip swarm-1\n)\n/monitor/targets\"\n\n\n\n\n\nYou should see two or three targets depending on whether Prometheus already sent the alert to de-scale the service (more on that soon).\n\n\nAutomatically Scaling Services\n\u00b6\n\n\nLet's go back to the Prometheus' alert screen.\n\n\nopen \n\"http://\n$(\ndocker-machine ip swarm-1\n)\n/monitor/alerts\"\n\n\n\n\n\nBy this time, the \ngodemo_main_resp_time_below\n alert should be red. The \ngo-demo\n service periodically pings itself and the response is faster than the twenty-five milliseconds limit we set (unless your laptop is very old and slow). As a result, Prometheus fired the alert to Alertmanager. It, in turn, evaluated the \nservice\n and \nscale\n labels and decided that it should send a POST request to Jenkins with parameters \nservice=go-demo_main&scale=-1\n.\n\n\nWe can confirm that the process worked by opening the Jenkins \nservice-scale\n activity screen.\n\n\nopen \n\"http://\n$(\ndocker-machine ip swarm-1\n)\n/jenkins/blue/organizations/jenkins/service-scale/activity\"\n\n\n\n\n\nYou should see that the new build was executed and, hopefully, it's green. If more than ten minutes passed, you might see a third build as well. If that's the case, we'll ignore it for now.\n\n\nPlease click the second (green) build followed with a click to the last step with the name \nPrint Message\n. The output should say that \ngo-demo_main was scaled from 3 to 2 replicas\n.\n\n\nLet's double check that's what truly happened.\n\n\ndocker stack ps -f desired-state\n=\nrunning go-demo\n\n\n\n\nThe output should be similar to the one that follows (IDs are removed for brevity).\n\n\nNAME           IMAGE                  NODE    DESIRED STATE CURRENT STATE         ERROR PORTS\ngo-demo_main.1 vfarcic/go-demo:latest swarm-2 Running       Running 2 minutes ago\ngo-demo_db.1   mongo:latest           swarm-2 Running       Running 3 minutes ago\ngo-demo_main.2 vfarcic/go-demo:latest swarm-3 Running       Running 2 minutes ago\n\n\n\n\nAs you can see, Prometheus used metrics to deduce that we have more replicas in the system than we really need since they respond very fast. As a result, if fired an alert to Alertmanager which executed a Jenkins build and our service was scaled down from three to two replicas.\n\n\nIf you take a closer look at the Alertmanager configuration, you'll notice that both the \nrepeat_interval\n and the \ngroup_interval\n are set to five minutes. If Prometheus continues firing the alert, Alertmanager will repeat the same process ten minutes later.\n\n\nPlease observe the Jenkins \nservice-scale\n screen. Ten minutes later a new build will start. However, since we are already running the minimum number of replicas, Jenkins will send a notification to Slack instead trying to continue de-scaling the service.\n\n\nPlease visit the \n#df-monitor-tests\n channel inside \ndevops20.slack.com\n and you should see a Slack notification stating that \ngo-demo_main could not be scaled\n. If this is your first visit to \ndevops20\n on Slack, you'll have to register through \nslack.devops20toolkit.com\n.\n\n\nLet's see what happens when response times of the service become too high. We'll send requests that will result in high response time and observe the behavior of the system.\n\n\nfor\n i in \n{\n1\n..30\n}\n;\n \ndo\n\n    \nDELAY\n=\n$\n[\n \n$RANDOM\n % \n6000\n \n]\n\n    curl \n\"http://\n$(\ndocker-machine ip swarm-1\n)\n/demo/hello?delay=\n$DELAY\n\"\n\n\ndone\n\n\n\n\n\nIf the service receives the \ndelay\n parameter, it goes to sleep for the specified number of milliseconds. The above commands sent thirty requests with a random delay between 0 and 6000 milliseconds.\n\n\nNow we can take a look at the alerts.\n\n\nopen \n\"http://\n$(\ndocker-machine ip swarm-1\n)\n/monitor/alerts\"\n\n\n\n\n\nThe \ngodemo_main_resp_time_above\n turned red indicating that the threshold is reached and Prometheus fired an alert to Alertmanager. If everything went as planned, Alertmanager should have sent a request to Jenkins. Let's confirm that indeed happened.\n\n\nopen \n\"http://\n$(\ndocker-machine ip swarm-1\n)\n/jenkins/blue/organizations/jenkins/service-scale/activity\"\n\n\n\n\n\nYou should see a new build. Please click it. The last step with the \nPrint Message\n header should state that \ngo-demo_main was scaled from 2 to 3 replicas\n.\n\n\nWe can confirm that the number of replicas indeed scaled to three by taking a look at the stack processes.\n\n\ndocker stack ps -f desired-state\n=\nrunning go-demo\n\n\n\n\nThe output should be similar to the one that follows (IDs are removed for brevity).\n\n\nNAME           IMAGE                  NODE    DESIRED STATE CURRENT STATE             ERROR PORTS\ngo-demo_main.1 vfarcic/go-demo:latest swarm-2 Running       Running about an hour ago\ngo-demo_db.1   mongo:latest           swarm-2 Running       Running about an hour ago\ngo-demo_main.2 vfarcic/go-demo:latest swarm-3 Running       Running about an hour ago\ngo-demo_main.3 vfarcic/go-demo:latest swarm-1 Running       Running 42 seconds ago\n\n\n\n\nWhat Now?\n\u00b6\n\n\nYou saw a simple example of a system that automatically scales and de-scales services. You should be able to expand on those examples and start building your own self-sufficient system that features not only self-healing provided with Docker Swarm but also self-adaptation based on scraped metrics.\n\n\nPlease remove the demo cluster we created and free your resources.\n\n\ndocker-machine rm -f swarm-1 swarm-2 swarm-3\n\n\n\n\nThe DevOps 2.2 Toolkit: Self-Healing Docker Clusters\n\u00b6\n\n\nThe tutorial you just read uses some of the concepts and exercises described in \nThe DevOps 2.2 Toolkit: Self-Healing Docker Clusters\n.\n\n\nIf you liked this article, you might be interested in \nThe DevOps 2.2 Toolkit: Self-Healing Docker Clusters\n book. The book goes beyond Docker and schedulers and tries to explore ways for building self-adaptive and self-healing Docker clusters. If you are a Docker user and want to explore advanced techniques for creating clusters and managing services, this book might be just what you're looking for.\n\n\nThe book is still under development. If you choose to become an early reader and influence the direction of the book, please get a copy from \nLeanPub\n. You will receive notifications whenever a new chapter is added.\n\n\nGive the book a try and let me know what you think.",
            "title": "Auto-Scaling Services Using Instrumented Metrics"
        },
        {
            "location": "/auto-scaling/#auto-scaling-docker-swarm-services-using-instrumented-metrics",
            "text": "Docker Swarm provides a solid mechanism that, among other things, makes sure that the specified number of replicas of a service is (almost) always running inside a cluster. It is performing self-healing out-of-the-box. However, that is often not enough. We need the system to adapt to changed conditions. We'll call this process self-adaptation.  In this tutorial, we'll go through one possible setup that allows self-adaptation of services based on their response time. That does not mean that response time metrics are the only ones we should use. Quite the contrary. However, we need to limit the scope of this tutorial and response times are probably one of the most commonly used metrics when applying self-adaptation.  The tools we'll use to setup a self-adaptive system are as follows.   Prometheus : Scrapes metrics and fires alerts when certain thresholds are reached.  Docker Flow Monitor : It extends Prometheus with capability to auto-configure itself.  Alertmanager : Receives alerts from Prometheus and forwards them to some other service depending on matching routes.  Jenkins : Executes scheduled or triggered jobs. We'll use it as the engine that will scale a service.  Docker Flow Proxy : It extends HAProxy with capability to auto-configure itself.  Docker Flow Swarm Listener : Listens to Swarm events and sends notifications when a service is created or updated. We'll use it to send notifications to  Docker Flow Monitor  and  Docker Flow Proxy .  go-demo : A demo service.    The examples that follow assume that you have Docker Machine version v0.8+ that includes Docker Engine v1.12+.   Info  If you are a Windows user, please run all the examples from  Git Bash  (installed through  Docker for Windows ). Also, make sure that your Git client is configured to check out the code  AS-IS . Otherwise, Windows might change carriage returns to the Windows format.",
            "title": "Auto-Scaling Docker Swarm Services Using Instrumented Metrics"
        },
        {
            "location": "/auto-scaling/#setting-up-a-cluster",
            "text": "Info  Feel free to skip this section if you already have a Swarm cluster that can be used for this tutorial   We'll create a Swarm cluster consisting of three nodes created with Docker Machine.  git clone https://github.com/vfarcic/docker-flow-monitor.git cd  docker-flow-monitor\n\n./scripts/dm-swarm.sh eval   $( docker-machine env swarm-1 )   We cloned the  vfarcic/docker-flow-monitor  repository. It contains all the scripts and stack files we'll use throughout this tutorial. Next, we executed the  dm-swarm.sh  script that created the cluster. Finally, we used the  eval  command to tell our local Docker client to use the remote Docker engine  swarm-1 .",
            "title": "Setting Up A Cluster"
        },
        {
            "location": "/auto-scaling/#deploying-docker-flow-proxy-dfp-and-docker-flow-swarm-listener-dfsl",
            "text": "Proxy is not strictly necessary for this tutorial. We're using it only as a convenient way to get a single access point to the cluster instead opening a different port for each publicly accessible service.  docker network create -d overlay proxy\n\ndocker stack deploy  \\ \n    -c stacks/docker-flow-proxy-mem.yml  \\ \n    proxy  The stack deployed two services;  proxy  and  swarm-listener . From now on, the proxy will be notified whenever a service is deployed or updated as long as it has the  com.df.notify  label set to  true . Please consult  docker-flow-proxy-mem.yml  for the full definition of the stack. For information about those two projects, please visit  proxy.dockerflow.com  and  swarmlistener.dockerflow.com .",
            "title": "Deploying Docker Flow Proxy (DFP) and Docker Flow Swarm Listener (DFSL)"
        },
        {
            "location": "/auto-scaling/#deploying-docker-flow-monitor-and-alertmanager",
            "text": "The next stack defines  Docker Flow Monitor  and  Alertmanager . Before we deploy the stack, we should create the  monitor  network that will allow Prometheus to scrape metrircs from exporters and instrumented services.  docker network create -d overlay monitor  Next we'll create  Alertmanager  configuration as a Docker secret. That way we won't need to create a new image with configuration or mount a volume.  echo   \"route:    group_by: [service,scale]    repeat_interval: 5m    group_interval: 5m    receiver: 'slack'    routes:    - match:        service: 'go-demo_main'        scale: 'up'      receiver: 'jenkins-go-demo_main-up'    - match:        service: 'go-demo_main'        scale: 'down'      receiver: 'jenkins-go-demo_main-down'  receivers:    - name: 'slack'      slack_configs:        - send_resolved: true          title: '[{{ .Status | toUpper }}] {{ .GroupLabels.service }} service is in danger!'          title_link: 'http:// $( docker-machine ip swarm-1 ) /monitor/alerts'          text: '{{ .CommonAnnotations.summary}}'          api_url: 'https://hooks.slack.com/services/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'    - name: 'jenkins-go-demo_main-up'      webhook_configs:        - send_resolved: false          url: 'http:// $( docker-machine ip swarm-1 ) /jenkins/job/service-scale/buildWithParameters?token=DevOps22&service=go-demo_main&scale=1'    - name: 'jenkins-go-demo_main-down'      webhook_configs:        - send_resolved: false          url: 'http:// $( docker-machine ip swarm-1 ) /jenkins/job/service-scale/buildWithParameters?token=DevOps22&service=go-demo_main&scale=-1'  \"   |  docker secret create alert_manager_config -  The configuration groups routes by  service  and  scale  labels. The  repeat_interval  and  group_interval  are both set to five minutes. In a production cluster,  repeat_interval  should be set to a much larger value (e.g.  1h ). We set it up to five minutes so that we can demonstrate different features of the system faster. Otherwise, we'd need to wait for over an hour to see different alerts in action.  The default receiver is  slack . As the result, any alert that does not match one of the  routes  will be sent to Slack.  The  routes  section defines two  match  entries. If the alert label  service  is set to  go-demo_main  and the label  scale  is  up , the receiver will be  jenkins-go-demo_main-up . Similarly, when the same service is associated with an alert but the  scale  label is set to  down , the receiver will be  jenkins-go-demo_main-down .  There are three receivers. The  slack  receiver will send notifications to Slack. As stated before, it's used only for alerts that do not  match  one of the  routes . Both  jenkins-go-demo_main-up  and  jenkins-go-demo_main-down  are sending a  POST  request to Jenkins job  service-scale . The only difference between the two is in the  scale  parameter. One will set it to  1  indicating that the  go-demo_main  service should be up-scaled by one and the other will set it to  -1  indicating that the service should de de-scaled by 1.  Please consult  configuration  section of Alertmanager documentation for more information about the options we used.  Now we can deploy the  monitor  stack.  DOMAIN = $( docker-machine ip swarm-1 )   \\ \n    docker stack deploy  \\ \n    -c stacks/docker-flow-monitor-slack.yml  \\ \n    monitor  The full definition of the stack that we just deployed can be found in  docker-flow-monitor-slack.yml . We'll comment only on a few interesting parts. The definition, limited to relevant parts, is as follows.  ...\n  monitor:\n    image: vfarcic/docker-flow-monitor\n    environment:\n      - LISTENER_ADDRESS=swarm-listener\n      - GLOBAL_SCRAPE_INTERVAL=${SCRAPE_INTERVAL:-10s}\n      - ARG_WEB_ROUTE-PREFIX=/monitor\n      - ARG_WEB_EXTERNAL-URL=http://${DOMAIN:-localhost}/monitor\n      - ARG_ALERTMANAGER_URL=http://alert-manager:9093\n    ...\n    deploy:\n      labels:\n        ...\n        - com.df.servicePath=/monitor\n        - com.df.serviceDomain=${DOMAIN:-localhost}\n        - com.df.port=9090\n      ...\n\n  alert-manager:\n    image: prom/alertmanager\n    networks:\n      - monitor\n    secrets:\n      - alert_manager_config\n    command: --config.file=/run/secrets/alert_manager_config --storage.path=/alertmanager\n\n  swarm-listener:\n    image: vfarcic/docker-flow-swarm-listener\n    ...\n    environment:\n      - DF_NOTIFY_CREATE_SERVICE_URL=http://monitor:8080/v1/docker-flow-monitor/reconfigure\n      - DF_NOTIFY_REMOVE_SERVICE_URL=http://monitor:8080/v1/docker-flow-monitor/remove\n    ...  Inside the  monitor  service, we used environment variables to provide initial Prometheus configuration. The labels will be used by  swarm  listener to notify the proxy about monitor's path, domain, and port.  The  alert-manager  service uses  alert_manager_config  secret as Alertmanager configuration file.  The  swarm-listener  service has  monitor  running on port  8080  as URL where notifications should be sent.  Please consult  Docker Flow Monitor documentation  for more information. If you haven't used it before, the  Running Docker Flow Monitor tutorial  might be a good starting point.  Let us confirm that the  monitor  stack is up and running.  docker stack ps monitor  Please wait a few moments if some of the replicas do not yet have the status set to  running .  Now that the  monitor  stack is up and running, we should proceed with deployment of Jenkins and its agent.",
            "title": "Deploying Docker Flow Monitor and Alertmanager"
        },
        {
            "location": "/auto-scaling/#deploying-jenkins",
            "text": "The Jenkins image we'll run already has all the plugins baked in. The administrative user and password will be retrieved from Docker secrets. A job that will scale and de-scale services is also defined inside the image. With those in place, we'll be able to skip manual setup.  echo   \"admin\"   |   \\ \n    docker secret create jenkins-user - echo   \"admin\"   |   \\ \n    docker secret create jenkins-pass - export   SLACK_IP = $( ping  \\ \n    -c  1  devops20.slack.com  \\ \n     |  awk -F '[()]'   '/PING/{print $2}' ) \n\ndocker stack deploy  \\ \n    -c stacks/jenkins-scale.yml jenkins  We created two secrets that define administrative username and password. The environment variable  SLACK_IP  might not be necessary. It's there just in case Docker Machine cannot resolve Slack. Finally, the last command deployed the  jenkins  stack.  I won't go into much detailed about the  jenkins  stack. If you're interested in the subject, you might want to read  Automating Jenkins Docker Setup  article or watch the  Jenkins Master As a Docker Service Running Inside a Docker for AWS Cluster  video. The only thing that truly matters is the  service-scale  job that we'll explore soon.  Before we proceed, please confirm that all the replicas of the stack are running.  docker stack ps jenkins  Once all the replicas of the stack are in the  running  state, we can open the  service-scale  job and take a quick look at its definition.   If you're a Windows user, Git Bash might not be able to use the  open  command. If that's the case, replace the  open  command with  echo . As a result, you'll get the full address that should be opened directly in your browser of choice.   open  \"http:// $( docker-machine ip swarm-1 ) /jenkins/job/service-scale/configure\"   You will be presented with a login screen. Please use  admin  as both username and password to authenticate.  Please click the  Pipeline  tab once you get inside the  service-scale  configuration screen.  The first half of the job is relatively straightforward. The job should be executed inside a  prod  agent (short for production). It defines two parameters. One holds the name of the service that should be scaled. The other expected a number of replicas that should be added or removed. If the value is positive, the service will be up-scaled. A negative value means that it should de-scale.  The job defines only one stage called  Scale . Inside it is a single step defined inside a  script . It executes  docker service inspect  command and retrieves the current number of replicas. It also retrieves  scaleMin  and  scaleMax  labels to discover the limits that should be applied to scaling. Without them, we would run a risk of scaling to infinity or de-scaling to zero replicas.  The desired number of replicas ( newReplicas ) is obtained by subtracting the current number of replicas with the  scale  parameter.  Once all the variables are set, it evaluates whether scaling would hit thresholds defined with  scaleMin  and  scaleMax . If it would, it throws an error which, later on in the  post  section, results in a message to Slack. If neither thresholds would be reached, a simple  docker service scale  command is executed.  Since Jenkins pipeline is defined using  Declarative syntax , the first execution needs to be manual so that it is correctly processed and the parameters are created.  Please open the  service-scale  activity screen.  open  \"http:// $( docker-machine ip swarm-1 ) /jenkins/blue/organizations/jenkins/service-scale/activity\"   Now click the  Run  button. A few moments later, you'll see that the build failed. Don't panic. That is expected. It's a workaround to bypass a bug and create the proper job definition with all the parameters. It will not fail again for the same reason.",
            "title": "Deploying Jenkins"
        },
        {
            "location": "/auto-scaling/#deploying-instrumented-service",
            "text": "The  go-demo  service is already instrumented. Among others, it request generates  resp_time  metrics with response time, service name, response code, and path labels.  We won't go into details of how the service was instrumented but only comment on a few snippets. The code of the whole service is in a single file  main.go . Do not be afraid! We're using Go only to demonstrate how instrumentation works. You can implement similar principles in almost any programming language. Hopefully, you should have no problem understanding the logic behind it even if Go is not your programming language of choice.  As an example, every request starting with the  /demo/hello  path is sent to the  HelloServer  function. The relevant part of the function is as follows.  func   HelloServer ( w   http . ResponseWriter ,   req   * http . Request )   { \n     start   :=   time . Now () \n     defer   func ()   {   recordMetrics ( start ,   req ,   http . StatusOK )   }() \n     ...  }   We record the time ( start ) and defer the invocation of the  recordMetric  function. In Go,  defer  means that the function will be executed at the end of the context it is defined in. Like that, we guarantee that the  recordMetrics  will be invoked after the request is processed and the response is sent back to the client.  The  recordMetric  function records (observes) the duration of the response by calculating the difference between the current and the start time. That observation is done with a few labels that will, later on, allow us to query metrics from Prometheus and define alerts.  func   recordMetrics ( start   time . Time ,   req   * http . Request ,   code   int )   { \n     duration   :=   time . Since ( start ) \n     histogram . With ( \n         prometheus . Labels { \n             \"service\" :   serviceName , \n             \"code\" :   fmt . Sprintf ( \"%d\" ,   code ), \n             \"method\" :   req . Method , \n             \"path\" :   req . URL . Path , \n         }, \n     ). Observe ( duration . Seconds ())  }   For more information, please consult  instrumentation  or  client libraries  pages of Prometheus documentation.  Now we can deploy the last stack. It will be the service we're hoping to scale based on response time metrics.  docker stack deploy  \\ \n    -c stacks/go-demo-instrument-alert-short.yml  \\ \n    go-demo  Please visit  go-demo-instrument-alert-short.yml  for the full stack definition. We'll comment only on service labels since the rest should be pretty straightforward.    main:\n    ...\n    deploy:\n      ...\n      labels:\n        - com.df.notify=true\n        - com.df.distribute=true\n        - com.df.servicePath=/demo\n        - com.df.port=8080\n        - com.df.scaleMin=2\n        - com.df.scaleMax=4\n        - com.df.scrapePort=8080\n        - com.df.alertName.1=mem_limit\n        - com.df.alertIf.1=@service_mem_limit:0.8\n        - com.df.alertFor.1=5m\n        - com.df.alertName.2=resp_time_above\n        - com.df.alertIf.2=@resp_time_above:0.1,5m,0.99\n        - com.df.alertName.3=resp_time_below\n        - com.df.alertIf.3=@resp_time_below:0.025,5m,0.75\n      ...  The  servicePath  and  port  label will be used by  Docker Flow Proxy  to configure itself and start forwarding requests coming to  /demo  to the  go-demo  service.  You already saw the usage of  scaleMin  and  scaleMax  labels. Jenkins uses them to decide whether the service should be scale or the number of replicas already reached the limits.  The  alertName ,  alertIf , and  alertFor  labels are the key to scaling. The define Prometheus alerts. The first one ( memlimit ) is already described in the  Running Docker Flow Monitor tutorial  so will skip it. The second ( resp_time_above ) defines alert that will be fired if the rate of response times of the  0.1  seconds bucket (100 milliseconds or faster) is above 99% ( 0.99 ) for over five minutes ( 5m ). Similarly, the  resp_time_below  alert will fire if the rate of response times of the  0.025  seconds bucket (25 milliseconds or faster) is below 75% ( 0.75 ) for over five minutes ( 5m ). In all the cases, we're using  AlertIf Parameter Shortcuts  that will be expanded into full Prometheus expressions.  Let's take a look at Prometheus alert screen.  open  \"http:// $( docker-machine ip swarm-1 ) /monitor/alerts\"   You should see three alerts that correspond to the three labels define in the  main  service of the  go-demo  stack.  Docker Flow Swarm Listener  detected the new service and sent those labels to  Docker Flow Monitor  which, in turn, converted them info Prometheus configuration.  If you expand the  godemo_main_resp_time_above  alert, you'll see that DFM translated the service labels into the alert definition that follows.  alert: godemo_main_resptimeabove\nexpr: sum(rate(http_server_resp_time_bucket{job=\"go-demo_main\",le=\"0.1\"}[5m]))\n  / sum(rate(http_server_resp_time_count{job=\"go-demo_main\"}[5m])) < 0.99\nlabels:\n  receiver: system\n  scale: up\n  service: go-demo_main\n  type: service\nannotations:\n  summary: Response time of the service go-demo_main is above 0.1  Similarly, the  godemo_main_resp_time_below  alert is defined as follows.  alert: godemo_main_resptimebelow\nexpr: sum(rate(http_server_resp_time_bucket{job=\"go-demo_main\",le=\"0.025\"}[5m]))\n  / sum(rate(http_server_resp_time_count{job=\"go-demo_main\"}[5m])) > 0.75\nlabels:\n  receiver: system\n  scale: down\n  service: go-demo_main\n  type: service\nannotations:\n  summary: Response time of the service go-demo_main is below 0.025  Let's confirm that the  go-demo  stack is up-and-running.  docker stack ps -f desired-state = running go-demo  You should see three replicas of the  go-demo_main  and one replica of the  go-demo_db  service. If that's not the case, please wait a while longer and repeat the  docker stack ps  command.  We should confirm that all the targets of the service are indeed registered.  open  \"http:// $( docker-machine ip swarm-1 ) /monitor/targets\"   You should see two or three targets depending on whether Prometheus already sent the alert to de-scale the service (more on that soon).",
            "title": "Deploying Instrumented Service"
        },
        {
            "location": "/auto-scaling/#automatically-scaling-services",
            "text": "Let's go back to the Prometheus' alert screen.  open  \"http:// $( docker-machine ip swarm-1 ) /monitor/alerts\"   By this time, the  godemo_main_resp_time_below  alert should be red. The  go-demo  service periodically pings itself and the response is faster than the twenty-five milliseconds limit we set (unless your laptop is very old and slow). As a result, Prometheus fired the alert to Alertmanager. It, in turn, evaluated the  service  and  scale  labels and decided that it should send a POST request to Jenkins with parameters  service=go-demo_main&scale=-1 .  We can confirm that the process worked by opening the Jenkins  service-scale  activity screen.  open  \"http:// $( docker-machine ip swarm-1 ) /jenkins/blue/organizations/jenkins/service-scale/activity\"   You should see that the new build was executed and, hopefully, it's green. If more than ten minutes passed, you might see a third build as well. If that's the case, we'll ignore it for now.  Please click the second (green) build followed with a click to the last step with the name  Print Message . The output should say that  go-demo_main was scaled from 3 to 2 replicas .  Let's double check that's what truly happened.  docker stack ps -f desired-state = running go-demo  The output should be similar to the one that follows (IDs are removed for brevity).  NAME           IMAGE                  NODE    DESIRED STATE CURRENT STATE         ERROR PORTS\ngo-demo_main.1 vfarcic/go-demo:latest swarm-2 Running       Running 2 minutes ago\ngo-demo_db.1   mongo:latest           swarm-2 Running       Running 3 minutes ago\ngo-demo_main.2 vfarcic/go-demo:latest swarm-3 Running       Running 2 minutes ago  As you can see, Prometheus used metrics to deduce that we have more replicas in the system than we really need since they respond very fast. As a result, if fired an alert to Alertmanager which executed a Jenkins build and our service was scaled down from three to two replicas.  If you take a closer look at the Alertmanager configuration, you'll notice that both the  repeat_interval  and the  group_interval  are set to five minutes. If Prometheus continues firing the alert, Alertmanager will repeat the same process ten minutes later.  Please observe the Jenkins  service-scale  screen. Ten minutes later a new build will start. However, since we are already running the minimum number of replicas, Jenkins will send a notification to Slack instead trying to continue de-scaling the service.  Please visit the  #df-monitor-tests  channel inside  devops20.slack.com  and you should see a Slack notification stating that  go-demo_main could not be scaled . If this is your first visit to  devops20  on Slack, you'll have to register through  slack.devops20toolkit.com .  Let's see what happens when response times of the service become too high. We'll send requests that will result in high response time and observe the behavior of the system.  for  i in  { 1 ..30 } ;   do \n     DELAY = $ [   $RANDOM  %  6000   ] \n    curl  \"http:// $( docker-machine ip swarm-1 ) /demo/hello?delay= $DELAY \"  done   If the service receives the  delay  parameter, it goes to sleep for the specified number of milliseconds. The above commands sent thirty requests with a random delay between 0 and 6000 milliseconds.  Now we can take a look at the alerts.  open  \"http:// $( docker-machine ip swarm-1 ) /monitor/alerts\"   The  godemo_main_resp_time_above  turned red indicating that the threshold is reached and Prometheus fired an alert to Alertmanager. If everything went as planned, Alertmanager should have sent a request to Jenkins. Let's confirm that indeed happened.  open  \"http:// $( docker-machine ip swarm-1 ) /jenkins/blue/organizations/jenkins/service-scale/activity\"   You should see a new build. Please click it. The last step with the  Print Message  header should state that  go-demo_main was scaled from 2 to 3 replicas .  We can confirm that the number of replicas indeed scaled to three by taking a look at the stack processes.  docker stack ps -f desired-state = running go-demo  The output should be similar to the one that follows (IDs are removed for brevity).  NAME           IMAGE                  NODE    DESIRED STATE CURRENT STATE             ERROR PORTS\ngo-demo_main.1 vfarcic/go-demo:latest swarm-2 Running       Running about an hour ago\ngo-demo_db.1   mongo:latest           swarm-2 Running       Running about an hour ago\ngo-demo_main.2 vfarcic/go-demo:latest swarm-3 Running       Running about an hour ago\ngo-demo_main.3 vfarcic/go-demo:latest swarm-1 Running       Running 42 seconds ago",
            "title": "Automatically Scaling Services"
        },
        {
            "location": "/auto-scaling/#what-now",
            "text": "You saw a simple example of a system that automatically scales and de-scales services. You should be able to expand on those examples and start building your own self-sufficient system that features not only self-healing provided with Docker Swarm but also self-adaptation based on scraped metrics.  Please remove the demo cluster we created and free your resources.  docker-machine rm -f swarm-1 swarm-2 swarm-3",
            "title": "What Now?"
        },
        {
            "location": "/auto-scaling/#the-devops-22-toolkit-self-healing-docker-clusters",
            "text": "The tutorial you just read uses some of the concepts and exercises described in  The DevOps 2.2 Toolkit: Self-Healing Docker Clusters .  If you liked this article, you might be interested in  The DevOps 2.2 Toolkit: Self-Healing Docker Clusters  book. The book goes beyond Docker and schedulers and tries to explore ways for building self-adaptive and self-healing Docker clusters. If you are a Docker user and want to explore advanced techniques for creating clusters and managing services, this book might be just what you're looking for.  The book is still under development. If you choose to become an early reader and influence the direction of the book, please get a copy from  LeanPub . You will receive notifications whenever a new chapter is added.  Give the book a try and let me know what you think.",
            "title": "The DevOps 2.2 Toolkit: Self-Healing Docker Clusters"
        },
        {
            "location": "/tutorial-flexible-labeling/",
            "text": "Flexible Labeling with Docker Flow Monitor\n\u00b6\n\n\nDocker Flow Monitor\n and \nDocker Flow Swarm Listener\n can be configured to allow for more flexible labeling of exporters. Please read the  \nRunning Docker Flow Monitor\n tutorial before reading this one. This tutorial focuses on configuring the stacks to allow for flexible labeling.\n\n\nSetting Up A Cluster\n\u00b6\n\n\n\n\nInfo\n\n\nFeel free to skip this section if you already have a Swarm cluster that can be used for this tutorial\n\n\n\n\nWe'll create a Swarm cluster consisting of three nodes created with Docker Machine.\n\n\ngit clone https://github.com/vfarcic/docker-flow-monitor.git\n\n\ncd\n docker-flow-monitor\n\n./scripts/dm-swarm.sh\n\n\neval\n \n$(\ndocker-machine env swarm-1\n)\n\n\n\n\n\nDeploying Docker Flow Monitor\n\u00b6\n\n\nWe will deploy \nstacks/docker-flow-monitor-flexible-labels.yml\n stack that contains three services: \nmonitor\n, \nalert-manager\n and \nswarm-listener\n. The \nswarm-listener\n service includes an additional environment variable: \nDF_INCLUDE_NODE_IP_INFO=true\n. This configures \nswarm-listener\n to send node information to \nmonitor\n as labels. The node's hostname will be included in every metric from the exporter with the label: \nnode\n.\n\n\nIn this tutorial, we will set up two additional labels: \nenv\n and \nmetricType\n. To enable these labels, we add the the environment variable: \nDF_SCRAPE_TARGET_LABELS=env,metricType\n to the \nmonitor\n service:\n\n\n...\n\n  \nmonitor\n:\n\n    \nimage\n:\n \nvfarcic/docker-flow-monitor:${TAG:-latest}\n\n    \nenvironment\n:\n\n      \n-\n \nDF_SCRAPE_TARGET_LABELS=env,metricType\n\n\n...\n\n\n\n\n\nThis sets up flexible labeling for our exporters. If an exporter defines a deploy label \ncom.df.env\n or \ncom.df.metricType\n, that label will be used by \nmonitor\n.\n\n\nWe will also configure DFM to include node and engine labels in our targets by adding the environment variable: \nDF_NODE_TARGET_LABELS=aws_region,role\n. \naws_region\n will be a label we will manually add to our nodes, and \nrole\n is a label that is already included by DFSL. For a full list of all default node labels, please consult the \nNode Notification docs\n.\n\n\n\n\nInfo\n\n\nOnly \n[a-zA-Z0-9_]\n are valid characters in prometheus labels.\n\n\n\n\nTo get the nodes information, DFSL is configured to send node events to DFM by setting \nDF_NOTIFY_CREATE_NODE_URL\n and \nDF_NOTIFY_REMOVE_NODE_URL\n:\n\n\n...\n\n  \nmonitor\n:\n\n    \nimage\n:\n \nvfarcic/docker-flow-monitor:${TAG:-latest}\n\n    \nenvironment\n:\n\n      \n-\n \nDF_NODE_TARGET_LABELS=aws_region,role\n\n      \n-\n \nDF_GET_NODES_URL=http://swarm-listener:8080/v1/docker-flow-swarm-listener/get-nodes\n\n  \n...\n\n  \nswarm-listener\n:\n\n    \nimage\n:\n \nvfarcic/docker-flow-swarm-listener\n\n    \nenvironment\n:\n\n      \n...\n\n      \n- DF_NOTIFY_CREATE_NODE_URL=http://monitor:8080/v1/docker-flow-monitor/node/reconfigure\n\n      \n- DF_NOTIFY_REMOVE_NODE_URL=http://monitor:8080/v1/docker-flow-monitor/node/remove\n\n      \n- DF_INCLUDE_NODE_IP_INFO=true\n\n\n...\n\n\n\n\n\nLet's deploy the \nmonitor\n stack:\n\n\ndocker network create -d overlay monitor\n\ndocker stack deploy \n\\\n\n    -c stacks/docker-flow-monitor-flexible-labels.yml \n\\\n\n    monitor\n\n\n\n\nAdding Labels to Nodes\n\u00b6\n\n\nWe will now add the \naws_region\n labels to our nodes. For DFM to recognize the labels, the labels must to be prefixed by \ncom.df.\n:\n\n\ndocker node update --label-add com.df.aws_region\n=\nus-east swarm-1\ndocker node update --label-add com.df.aws_region\n=\nus-east swarm-2\ndocker node update --label-add com.df.aws_region\n=\nus-west swarm-3\n\n\n\n\nCollecting Metrics and Defining Alerts\n\u00b6\n\n\nWe will deploy exporters stack defined in \nstacks/exporters-tutorial-flexible-labels.yml\n,  two containing two services: \ncadvisor\n and \nnode-exporter\n.\n\n\nThe definition of the \ncadvisor\n service contains additional deploy labels:\n\n\n  \ncadvisor\n:\n\n    \nimage\n:\n \ngoogle/cadvisor\n\n    \nnetworks\n:\n\n      \n-\n \nmonitor\n\n    \n...\n\n    \ndeploy\n:\n\n      \nmode\n:\n \nglobal\n\n      \nlabels\n:\n\n        \n...\n\n        \n- com.df.scrapeNetwork=monitor\n\n        \n- com.df.env=prod\n\n        \n- com.df.metricType=system\n\n\n\n\n\nThe \ncom.df.scrapeNetwork\n deploy label tells \nswarm-listener\n to use \ncadvisor\n's IP on the \nmonitor\n network. This is important because the \nmonitor\n service is using the \nmonitor\n network to scrape \ncadvisor\n. The \ncom.df.env=prod\n and \ncom.df.metricType=system\n deploy labels configures flexible labeling for \ncadvisor\n.\n\n\nThe second service, \nnode-exporter\n is also configured with flexiable labels:\n\n\n  \nnode-exporter\n:\n\n    \nimage\n:\n \nbasi/node-exporter\n\n    \nnetworks\n:\n\n      \n-\n \nmonitor\n\n    \n...\n\n    \ndeploy\n:\n\n      \nmode\n:\n \nglobal\n\n      \nlabels\n:\n\n        \n...\n\n        \n- com.df.scrapeNetwork=monitor\n\n        \n- com.df.env=dev\n\n        \n- com.df.metricType=system\n\n\n\n\n\nLet's deploy the \nexporter\n stack\n\n\ndocker stack deploy \n\\\n\n    -c stacks/exporters-tutorial-flexible-labels.yml \n\\\n\n    exporter\n\n\n\n\nPlease wait until the service in the stack are up-and-running. You can check their status by executing \ndocker stack ps exporter\n.\n\n\nNow we can open the \nPrometheus\n targets page from a browser.\n\n\n\n\nIf you're a Windows user, Git Bash might not be able to use the \nopen\n command. If that's the case, replace the \nopen\n command with \necho\n. As a result, you'll get the full address that should be opened directly in your browser of choice.\n\n\n\n\nopen \n\"http://\n$(\ndocker-machine ip swarm-1\n)\n:9090/targets\"\n\n\n\n\n\nYou should see a targets page similar to the following:\n\n\n\n\nEach service is labeled with its associated \ncom.df.env\n or \ncom.df.metricType\n deploy label. In addition, the \nnode\n label is the hostname the service is running on. The node labels \naws_region\n and \nrole\n are also included for each target.\n\n\nWhat Now?\n\u00b6\n\n\nDocker Flow Monitors\n's flexible labeling feature provides more information about your services. Please consult the documentation for any additional information you might need. Feel free to open \nan issue\n if you require additional info, if you find a bug, or if you have a feature request.\n\n\nBefore you go, please remove the cluster we created and free those resources for something else.\n\n\ndocker-machine rm -f swarm-1 swarm-2 swarm-3",
            "title": "Flexible Labeling with Docker Flow Monitor"
        },
        {
            "location": "/tutorial-flexible-labeling/#flexible-labeling-with-docker-flow-monitor",
            "text": "Docker Flow Monitor  and  Docker Flow Swarm Listener  can be configured to allow for more flexible labeling of exporters. Please read the   Running Docker Flow Monitor  tutorial before reading this one. This tutorial focuses on configuring the stacks to allow for flexible labeling.",
            "title": "Flexible Labeling with Docker Flow Monitor"
        },
        {
            "location": "/tutorial-flexible-labeling/#setting-up-a-cluster",
            "text": "Info  Feel free to skip this section if you already have a Swarm cluster that can be used for this tutorial   We'll create a Swarm cluster consisting of three nodes created with Docker Machine.  git clone https://github.com/vfarcic/docker-flow-monitor.git cd  docker-flow-monitor\n\n./scripts/dm-swarm.sh eval   $( docker-machine env swarm-1 )",
            "title": "Setting Up A Cluster"
        },
        {
            "location": "/tutorial-flexible-labeling/#deploying-docker-flow-monitor",
            "text": "We will deploy  stacks/docker-flow-monitor-flexible-labels.yml  stack that contains three services:  monitor ,  alert-manager  and  swarm-listener . The  swarm-listener  service includes an additional environment variable:  DF_INCLUDE_NODE_IP_INFO=true . This configures  swarm-listener  to send node information to  monitor  as labels. The node's hostname will be included in every metric from the exporter with the label:  node .  In this tutorial, we will set up two additional labels:  env  and  metricType . To enable these labels, we add the the environment variable:  DF_SCRAPE_TARGET_LABELS=env,metricType  to the  monitor  service:  ... \n   monitor : \n     image :   vfarcic/docker-flow-monitor:${TAG:-latest} \n     environment : \n       -   DF_SCRAPE_TARGET_LABELS=env,metricType  ...   This sets up flexible labeling for our exporters. If an exporter defines a deploy label  com.df.env  or  com.df.metricType , that label will be used by  monitor .  We will also configure DFM to include node and engine labels in our targets by adding the environment variable:  DF_NODE_TARGET_LABELS=aws_region,role .  aws_region  will be a label we will manually add to our nodes, and  role  is a label that is already included by DFSL. For a full list of all default node labels, please consult the  Node Notification docs .   Info  Only  [a-zA-Z0-9_]  are valid characters in prometheus labels.   To get the nodes information, DFSL is configured to send node events to DFM by setting  DF_NOTIFY_CREATE_NODE_URL  and  DF_NOTIFY_REMOVE_NODE_URL :  ... \n   monitor : \n     image :   vfarcic/docker-flow-monitor:${TAG:-latest} \n     environment : \n       -   DF_NODE_TARGET_LABELS=aws_region,role \n       -   DF_GET_NODES_URL=http://swarm-listener:8080/v1/docker-flow-swarm-listener/get-nodes \n   ... \n   swarm-listener : \n     image :   vfarcic/docker-flow-swarm-listener \n     environment : \n       ... \n       - DF_NOTIFY_CREATE_NODE_URL=http://monitor:8080/v1/docker-flow-monitor/node/reconfigure \n       - DF_NOTIFY_REMOVE_NODE_URL=http://monitor:8080/v1/docker-flow-monitor/node/remove \n       - DF_INCLUDE_NODE_IP_INFO=true  ...   Let's deploy the  monitor  stack:  docker network create -d overlay monitor\n\ndocker stack deploy  \\ \n    -c stacks/docker-flow-monitor-flexible-labels.yml  \\ \n    monitor",
            "title": "Deploying Docker Flow Monitor"
        },
        {
            "location": "/tutorial-flexible-labeling/#adding-labels-to-nodes",
            "text": "We will now add the  aws_region  labels to our nodes. For DFM to recognize the labels, the labels must to be prefixed by  com.df. :  docker node update --label-add com.df.aws_region = us-east swarm-1\ndocker node update --label-add com.df.aws_region = us-east swarm-2\ndocker node update --label-add com.df.aws_region = us-west swarm-3",
            "title": "Adding Labels to Nodes"
        },
        {
            "location": "/tutorial-flexible-labeling/#collecting-metrics-and-defining-alerts",
            "text": "We will deploy exporters stack defined in  stacks/exporters-tutorial-flexible-labels.yml ,  two containing two services:  cadvisor  and  node-exporter .  The definition of the  cadvisor  service contains additional deploy labels:     cadvisor : \n     image :   google/cadvisor \n     networks : \n       -   monitor \n     ... \n     deploy : \n       mode :   global \n       labels : \n         ... \n         - com.df.scrapeNetwork=monitor \n         - com.df.env=prod \n         - com.df.metricType=system   The  com.df.scrapeNetwork  deploy label tells  swarm-listener  to use  cadvisor 's IP on the  monitor  network. This is important because the  monitor  service is using the  monitor  network to scrape  cadvisor . The  com.df.env=prod  and  com.df.metricType=system  deploy labels configures flexible labeling for  cadvisor .  The second service,  node-exporter  is also configured with flexiable labels:     node-exporter : \n     image :   basi/node-exporter \n     networks : \n       -   monitor \n     ... \n     deploy : \n       mode :   global \n       labels : \n         ... \n         - com.df.scrapeNetwork=monitor \n         - com.df.env=dev \n         - com.df.metricType=system   Let's deploy the  exporter  stack  docker stack deploy  \\ \n    -c stacks/exporters-tutorial-flexible-labels.yml  \\ \n    exporter  Please wait until the service in the stack are up-and-running. You can check their status by executing  docker stack ps exporter .  Now we can open the  Prometheus  targets page from a browser.   If you're a Windows user, Git Bash might not be able to use the  open  command. If that's the case, replace the  open  command with  echo . As a result, you'll get the full address that should be opened directly in your browser of choice.   open  \"http:// $( docker-machine ip swarm-1 ) :9090/targets\"   You should see a targets page similar to the following:   Each service is labeled with its associated  com.df.env  or  com.df.metricType  deploy label. In addition, the  node  label is the hostname the service is running on. The node labels  aws_region  and  role  are also included for each target.",
            "title": "Collecting Metrics and Defining Alerts"
        },
        {
            "location": "/tutorial-flexible-labeling/#what-now",
            "text": "Docker Flow Monitors 's flexible labeling feature provides more information about your services. Please consult the documentation for any additional information you might need. Feel free to open  an issue  if you require additional info, if you find a bug, or if you have a feature request.  Before you go, please remove the cluster we created and free those resources for something else.  docker-machine rm -f swarm-1 swarm-2 swarm-3",
            "title": "What Now?"
        },
        {
            "location": "/config/",
            "text": "Configuring Docker Flow Monitor\n\u00b6\n\n\nDocker Flow Monitor\n can be configured through Docker environment variables and/or by creating a new image based on \nvfarcic/docker-flow-monitor\n.\n\n\nStartup Arguments\n\u00b6\n\n\nEnvironment variables prefixed will \nARG_\n are used instead Prometheus startup arguments.\n\n\nThe formatting rules for the \nARG\n variables are as follows:\n\n\n\n\nVariable name has to be prefixed with \nARG_\n.\n\n\nUnderscores (\n_\n) will be replaced with dots (\n.\n).\n\n\nCapital letters will be transformed to lower case.\n\n\n\n\nFor example, if environment variables \nARG_WEB_ROUTE-PREFIX=/monitor\n and \nARG_WEB_EXTERNAL-URL=http://localhost/monitor\n are defined, Prometheus will be started with the arguments \nweb.route-prefix=/monitor\n and \nweb.external-url=http://localhost/monitor\n. The result would be Prometheus initialization equivalent to the command that follows.\n\n\nprometheus --web.route-prefix\n=\n/monitor --web.external-url\n=\nhttp://localhost/monitor\n\n\n\n\nARG\n variables defined by default are as follows.\n\n\nARG_CONFIG_FILE=/etc/prometheus/prometheus.yml\nARG_STORAGE_TSDB_PATH=/prometheus\nARG_WEB_CONSOLE_LIBRARIES=/usr/share/prometheus/console_libraries\nARG_WEB_CONSOLE_TEMPLATES=/usr/share/prometheus/consoles\n\n\n\n\nConfiguration\n\u00b6\n\n\nEnvironment variables prefixed with \nGLOBAL__\n, \nALERTING__\n, \nSCRAPE_CONFIGS__\n, \nREMOTE_WRITE__\n, and \nREMOTE_READ__\n are used to configure Prometheus.\n\n\nThe formatting rules for these variable are as follows:\n\n\n\n\nEnvironment keys will be transformed to lowercase.\n\n\nDouble underscore is used to go one level deeper in a yaml dictionary.\n\n\nA single underscore followed by a number indicates the position of an array.\n\n\n\n\nExamples\n\u00b6\n\n\nThe following are examples of using environmental variables to configure Prometheus. Pleaes consult the Prometheus configuration \ndocumentation\n for all configuration options.\n\n\n\n\nGLOBAL__SCRAPE_INTERVAL=10s\n\n\n\n\nglobal\n:\n\n  \nscrape_interval\n:\n \n10s\n\n\n\n\n\n\n\nGLOBAL__EXTERNAL_LABELS=cluster=swarm\n\n\n\n\nglobal\n:\n\n  \nexternal_labels\n:\n\n    \ncluster\n:\n \nswarm\n\n    \ntype\n:\n \nproduction\n\n\n\n\n\nThis is \nNOT\n \nGLOBAL__EXTERNAL_LABELS__CLUSTER=swarm\n because \nCLUSTER\n is not a standard Prometheus configuration. The \nexternal_labels\n option is a list of key values as shown in their documentation:\n\n\nexternal_labels\n:\n\n  \n[\n \n<labelname>\n:\n \n<labelvalue> ...\n \n]\n\n\n\n\n\n\n\nREMOTE_WRITE_1__URL=http://first.acme.com/write\n, \nREMOTE_WRITE_1__REMOTE_TIMEOUT=10s\n,\n\nREMOTE_WRITE_2__URL=http://second.acme.com/write\n\n\n\n\nremote_write\n:\n\n\n-\n \nurl\n:\n \nhttp://acme.com/write\n\n  \nremote_timeout\n:\n \n30s\n\n\n-\n \nurl\n:\n \nhttp://second.acme.com/write\n\n\n\n\n\nTrailing numbers in the \nREMOTE_WRITE_1\n and \nREMOTE_WRITE_2\n prefixes dictates the position of the array of dictionaries.\n\n\n\n\nREMOTE_WRITE_1__WRITE_RELABEL_CONFIGS_1__SOURCE_LABELS_1=label1\n\n\n\n\nremote_write\n:\n\n\n-\n \nwrite_relabel_configs\n:\n\n  \n-\n \nsource_labels\n:\n \n[\nlabel1\n]\n\n\n\n\n\nScrape Environment Configuration\n\u00b6\n\n\nIt is possible to add servers that are not part of the Docker Swarm Cluster just adding the variables \nSCRAPE_PORT\n and \nSERVICE_NAME\n on the environment. The project is going to use the \nstatic_configs\n configuration.\n\n\nSCRAPE_PORT_1=1234\nSERVICE_NAME_1=myservice.acme.com\nSCRAPE_PORT_2=1234\nSERVICE_NAME_2=myservice2.acme.com\n\n\n\n\nYou can also add a service via \napi\n using the \nreconfigure\n entry point.\n\n\ncurl \n`\n[\nIP_OF_ONE_OF_SWARM_NODES\n]\n:8080/v1/docker-flow-monitor/reconfigure?scrapePort\n=[\nPORT\n]\n&\nserviceName\n=[\nIP_OR_DOMAIN\n]\n&\nscrapeType\n=\nstatic_configs\n\n\n\n\nPlease consult \nPrometheus Configuration\n for more information about the available options.\n\n\nScrape Secret Configuration\n\u00b6\n\n\nAdditional scrapes can be added through files prefixed with \nscrape_\n. By default, all such files located in \n/run/secrets\n are automatically added to the \nscrape_configs\n section of the configuration. The directory can be changed by setting a different value to the environment variable \nCONFIGS_DIR\n.\n\n\nThe simplest way to add scrape configs is to use Docker \nsecrets\n or \nconfigs\n.\n\n\nScrape Label Configuration With Service and Node Labels\n\u00b6\n\n\nWhen using a version of \nDocker Flow Swarm Listener\n, DFSL, newer than \n18.03.20-39\n, you can configure DFSL to send node information to \nDocker Flow Monitor\n, DFM. This can be done by setting \nDF_INCLUDE_NODE_IP_INFO\n to \ntrue\n in the DFSL environment. DFM will automatically display the node hostnames as a label for each prometheus target. The \nDF_SCRAPE_TARGET_LABELS\n env variable allows for additional labels to be displayed. For example, if a service has env variables \ncom.df.env=prod\n and \ncom.df.domain=frontend\n, you can set \nDF_SCRAPE_TARGET_LABELS=env,domain\n in DFM to display the \nprod\n and \nfrontend\n labels in prometheus.\n\n\nIn addition to service labels, DFM can be configured to import node and engine labels prefixed with \ncom.df.\n as prometheus labels for our targets. First, configure DFSL to push node events to DFM by setting \nDF_NOTIFY_CREATE_NODE_URL=[MONITOR_IP]:[MONITOR_PORT]/v1/docker-flow-monitor/node/reconfigure\n and \nDF_NOTIFY_REMOVE_NODE_URL=[MONITOR_IP]:[MONITOR_PORT]/v1/docker-flow-monitor/node/remove\n in DFSL. Then, in DFM, set \nDF_GET_NODES_URL=[SWARM_LISTENER_IP]:[SWARM_LISTENER_PORT]/v1/docker-flow-swarm-listener/get-nodes\n and set \nDF_NODE_TARGET_LABELS\n env variable to a comma seperate list of labels use. For example, if our node has label \ncom.df.aws-region=us-east-1\n and we set \nDF_NODE_TARGET_LABELS=aws-region\n, your prometheus targets on that node will include \naws-region=us-east-1\n. For more information, please visit the \nFlexiable Labeling tutorial\n.\n\n\n\n\nInfo\n\n\nOnly \n[a-zA-Z0-9_]\n are valid characters in prometheus labels in \nDF_NODE_TARGET_LABELS\n and \nDF_SCRAPE_TARGET_LABELS\n.",
            "title": "Configuration"
        },
        {
            "location": "/config/#configuring-docker-flow-monitor",
            "text": "Docker Flow Monitor  can be configured through Docker environment variables and/or by creating a new image based on  vfarcic/docker-flow-monitor .",
            "title": "Configuring Docker Flow Monitor"
        },
        {
            "location": "/config/#startup-arguments",
            "text": "Environment variables prefixed will  ARG_  are used instead Prometheus startup arguments.  The formatting rules for the  ARG  variables are as follows:   Variable name has to be prefixed with  ARG_ .  Underscores ( _ ) will be replaced with dots ( . ).  Capital letters will be transformed to lower case.   For example, if environment variables  ARG_WEB_ROUTE-PREFIX=/monitor  and  ARG_WEB_EXTERNAL-URL=http://localhost/monitor  are defined, Prometheus will be started with the arguments  web.route-prefix=/monitor  and  web.external-url=http://localhost/monitor . The result would be Prometheus initialization equivalent to the command that follows.  prometheus --web.route-prefix = /monitor --web.external-url = http://localhost/monitor  ARG  variables defined by default are as follows.  ARG_CONFIG_FILE=/etc/prometheus/prometheus.yml\nARG_STORAGE_TSDB_PATH=/prometheus\nARG_WEB_CONSOLE_LIBRARIES=/usr/share/prometheus/console_libraries\nARG_WEB_CONSOLE_TEMPLATES=/usr/share/prometheus/consoles",
            "title": "Startup Arguments"
        },
        {
            "location": "/config/#configuration",
            "text": "Environment variables prefixed with  GLOBAL__ ,  ALERTING__ ,  SCRAPE_CONFIGS__ ,  REMOTE_WRITE__ , and  REMOTE_READ__  are used to configure Prometheus.  The formatting rules for these variable are as follows:   Environment keys will be transformed to lowercase.  Double underscore is used to go one level deeper in a yaml dictionary.  A single underscore followed by a number indicates the position of an array.",
            "title": "Configuration"
        },
        {
            "location": "/config/#examples",
            "text": "The following are examples of using environmental variables to configure Prometheus. Pleaes consult the Prometheus configuration  documentation  for all configuration options.   GLOBAL__SCRAPE_INTERVAL=10s   global : \n   scrape_interval :   10s    GLOBAL__EXTERNAL_LABELS=cluster=swarm   global : \n   external_labels : \n     cluster :   swarm \n     type :   production   This is  NOT   GLOBAL__EXTERNAL_LABELS__CLUSTER=swarm  because  CLUSTER  is not a standard Prometheus configuration. The  external_labels  option is a list of key values as shown in their documentation:  external_labels : \n   [   <labelname> :   <labelvalue> ...   ]    REMOTE_WRITE_1__URL=http://first.acme.com/write ,  REMOTE_WRITE_1__REMOTE_TIMEOUT=10s , REMOTE_WRITE_2__URL=http://second.acme.com/write   remote_write :  -   url :   http://acme.com/write \n   remote_timeout :   30s  -   url :   http://second.acme.com/write   Trailing numbers in the  REMOTE_WRITE_1  and  REMOTE_WRITE_2  prefixes dictates the position of the array of dictionaries.   REMOTE_WRITE_1__WRITE_RELABEL_CONFIGS_1__SOURCE_LABELS_1=label1   remote_write :  -   write_relabel_configs : \n   -   source_labels :   [ label1 ]",
            "title": "Examples"
        },
        {
            "location": "/config/#scrape-environment-configuration",
            "text": "It is possible to add servers that are not part of the Docker Swarm Cluster just adding the variables  SCRAPE_PORT  and  SERVICE_NAME  on the environment. The project is going to use the  static_configs  configuration.  SCRAPE_PORT_1=1234\nSERVICE_NAME_1=myservice.acme.com\nSCRAPE_PORT_2=1234\nSERVICE_NAME_2=myservice2.acme.com  You can also add a service via  api  using the  reconfigure  entry point.  curl  ` [ IP_OF_ONE_OF_SWARM_NODES ] :8080/v1/docker-flow-monitor/reconfigure?scrapePort =[ PORT ] & serviceName =[ IP_OR_DOMAIN ] & scrapeType = static_configs  Please consult  Prometheus Configuration  for more information about the available options.",
            "title": "Scrape Environment Configuration"
        },
        {
            "location": "/config/#scrape-secret-configuration",
            "text": "Additional scrapes can be added through files prefixed with  scrape_ . By default, all such files located in  /run/secrets  are automatically added to the  scrape_configs  section of the configuration. The directory can be changed by setting a different value to the environment variable  CONFIGS_DIR .  The simplest way to add scrape configs is to use Docker  secrets  or  configs .",
            "title": "Scrape Secret Configuration"
        },
        {
            "location": "/config/#scrape-label-configuration-with-service-and-node-labels",
            "text": "When using a version of  Docker Flow Swarm Listener , DFSL, newer than  18.03.20-39 , you can configure DFSL to send node information to  Docker Flow Monitor , DFM. This can be done by setting  DF_INCLUDE_NODE_IP_INFO  to  true  in the DFSL environment. DFM will automatically display the node hostnames as a label for each prometheus target. The  DF_SCRAPE_TARGET_LABELS  env variable allows for additional labels to be displayed. For example, if a service has env variables  com.df.env=prod  and  com.df.domain=frontend , you can set  DF_SCRAPE_TARGET_LABELS=env,domain  in DFM to display the  prod  and  frontend  labels in prometheus.  In addition to service labels, DFM can be configured to import node and engine labels prefixed with  com.df.  as prometheus labels for our targets. First, configure DFSL to push node events to DFM by setting  DF_NOTIFY_CREATE_NODE_URL=[MONITOR_IP]:[MONITOR_PORT]/v1/docker-flow-monitor/node/reconfigure  and  DF_NOTIFY_REMOVE_NODE_URL=[MONITOR_IP]:[MONITOR_PORT]/v1/docker-flow-monitor/node/remove  in DFSL. Then, in DFM, set  DF_GET_NODES_URL=[SWARM_LISTENER_IP]:[SWARM_LISTENER_PORT]/v1/docker-flow-swarm-listener/get-nodes  and set  DF_NODE_TARGET_LABELS  env variable to a comma seperate list of labels use. For example, if our node has label  com.df.aws-region=us-east-1  and we set  DF_NODE_TARGET_LABELS=aws-region , your prometheus targets on that node will include  aws-region=us-east-1 . For more information, please visit the  Flexiable Labeling tutorial .   Info  Only  [a-zA-Z0-9_]  are valid characters in prometheus labels in  DF_NODE_TARGET_LABELS  and  DF_SCRAPE_TARGET_LABELS .",
            "title": "Scrape Label Configuration With Service and Node Labels"
        },
        {
            "location": "/usage/",
            "text": "Usage\n\u00b6\n\n\nDocker Flow Monitor\n can be controlled by sending HTTP requests or through Docker Service labels when combined with \nDocker Flow Swarm Listener\n.\n\n\nReconfigure\n\u00b6\n\n\nReconfigure\n endpoint can be used to send requests to \nDocker Flow Monitor\n with the goal of adding or modifying existing scrape targets and alerts. Parameters are divided into \nscrape\n and \nalert\n groups.\n\n\nQuery parameters that follow should be added to the base address \n[MONITOR_IP]:[MONITOR_PORT]/v1/docker-flow-monitor/reconfigure\n.\n\n\nScrape Parameters\n\u00b6\n\n\n\n\nTip\n\n\nDefines Prometheus scrape targets\n\n\n\n\n\n\n\n\n\n\nQuery\n\n\nDescription\n\n\nRequired\n\n\n\n\n\n\n\n\n\n\nmetricsPath\n\n\nThe path of the metrics endpoint. Defaults to \n/metrics\n.\n\n\nNo\n\n\n\n\n\n\nscrapeInterval\n\n\nHow frequently to scrape targets from this job.\n\n\nNo\n\n\n\n\n\n\nscrapeTimeout\n\n\nPer-scrape timeout when scraping this job.\n\n\nNo\n\n\n\n\n\n\nscrapePort\n\n\nThe port through which metrics are exposed.\n\n\nYes\n\n\n\n\n\n\nserviceName\n\n\nThe name of the service that exports metrics.\n\n\nYes\n\n\n\n\n\n\nscrapeType\n\n\nA set of targets and parameters describing how to scrape metrics.\n\n\nNo\n\n\n\n\n\n\n\n\nYou can find more about scrapeType's on \nScrape Config\n.\n\n\nAlert Parameters\n\u00b6\n\n\n\n\nTip\n\n\nDefines Prometheus alerts\n\n\n\n\n\n\n\n\n\n\nQuery\n\n\nDescription\n\n\nRequired\n\n\n\n\n\n\n\n\n\n\nalertAnnotations\n\n\nThis parameter is translated to Prometheus alert \nANNOTATIONS\n statement. Annotations are used to store longer additional information.\nExample:\n \nsummary=Service memory is high,description=Do something or start panicking\n\n\nNo\n\n\n\n\n\n\nalertFor\n\n\nThis parameter is translated to Prometheus alert \nFOR\n statement. It causes Prometheus to wait for a certain duration between first encountering a new expression output vector element (like an instance with a high HTTP error rate) and counting an alert as firing for this element. Elements that are active, but not firing yet, are in pending state. This parameter expects a number with time suffix (e.g. \ns\n for seconds, \nm\n for minutes).\nExample:\n \n30s\n\n\nNo\n\n\n\n\n\n\nalertIf\n\n\nThis parameter is translated to Prometheus alert \nIF\n statement. It is an expression that will be evaluated and, if it returns \ntrue\n, an alert will be fired.\nExample: \ncontainer_memory_usage_bytes{container_label_com_docker_swarm_service_name=\"go-demo\"}/container_spec_memory_limit_bytes{container_label_com_docker_swarm_service_name=\"go-demo\"} > 0.8\n\n\nYes\n\n\n\n\n\n\nalertLabels\n\n\nThis parameter is translated to Prometheus alert \nLABELS\n statement. It allows specifying a set of additional labels to be attached to the alert. Multiple labels can be separated with comma (\n,\n).\nExample:\n \nseverity=high,receiver=system\n\n\nNo\n\n\n\n\n\n\nalertName\n\n\nThe name of the alert. It is combined with the \nserviceName\n thus producing an unique identifier.\nExample:\n \nmemoryAlert\n\n\nYes\n\n\n\n\n\n\nserviceName\n\n\nThe name of the service. It is combined with the \nalertName\n thus producing an unique identifier.\nExample:\n \ngo-demo\n\n\nYes\n\n\n\n\n\n\nalertPersistent\n\n\nWhen set to \ntrue\n, the alert will persist when the service is scaled to zero replicas.\nExample:\n \ntrue\n\n\nNo\n\n\n\n\n\n\n\n\nThose parameters can be indexed so that multiple alerts can be defined for a service. Indexing is sequential and starts from 1. An example of indexed \nalertName\n could be \nalertName.1=memload\n and \nalertName.2=diskload\n.\n\n\nPlease visit \nAlerting Overview\n for more information about the rules for defining Prometheus alerts.\n\n\nAlertIf Parameter Shortcuts\n\u00b6\n\n\n\n\nTip\n\n\nAllows short specification of commonly used \nalertIf\n parameters\n\n\n\n\n\n\n\n\n\n\nShortcut\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n@node_fs_limit:[PERCENTAGE]\n\n\nWhether node file system usage is over specified percentage of the total available file system size.\nRequirements:\n \nnode-exporter\n metrics\n[PERCENTAGE] must be specified as a decimal value (e.g. \n0.8\n equals \n80%\n).\nExample:\n \n@node_fs_limit:0.8\n would be expanded to \n(node_filesystem_size{fstype=\"aufs\", job=\"my-service\"} - node_filesystem_free{fstype=\"aufs\", job=\"my-service\"}) / node_filesystem_size{fstype=\"aufs\", job=\"my-service\"} > 0.8\n.\n\n\n\n\n\n\n@node_mem_limit:[PERCENTAGE]\n\n\nWhether node memory usage is over specified percentage of the total node memory.\nRequirements:\n \nnode-exporter\n metrics\n[PERCENTAGE] must be specified as a decimal value (e.g. \n0.8\n equals \n80%\n).\nExample:\n \n@node_mem_limit:0.8\n would be expanded to \n(sum by (instance) (node_memory_MemTotal{job=\"my-service\"}) - sum by (instance) (node_memory_MemFree{job=\"my-service\"} + node_memory_Buffers{job=\"my-service\"} + node_memory_Cached{job=\"my-service\"})) / sum by (instance) (node_memory_MemTotal{job=\"my-service\"}) > 0.8\n.\n\n\n\n\n\n\n@node_mem_limit_total_above:[PERCENTAGE]\n\n\nWhether memory usage of all the nodes is over the specified percentage of the total memory.\nRequirements:\n \nnode-exporter\n metrics\n[PERCENTAGE] must be specified as a decimal value (e.g. \n0.8\n equals \n80%\n).\nExample:\n \n@node_mem_limit_total_above:0.8\n would be expanded to \n(sum(node_memory_MemTotal{job=\"my-service\"}) - sum(node_memory_MemFree{job=\"my-service\"} + node_memory_Buffers{job=\"my-service\"} + node_memory_Cached{job=\"my-service\"})) / sum(node_memory_MemTotal{job=\"my-service\"}) > 0.8\n.\n\n\n\n\n\n\n@node_mem_limit_total_below:[PERCENTAGE]\n\n\nWhether memory usage of all the nodes is below the specified percentage of the total memory.\nRequirements:\n \nnode-exporter\n metrics\n[PERCENTAGE] must be specified as a decimal value (e.g. \n0.8\n equals \n80%\n).\nExample:\n \n@node_mem_limit_total_below:0.4\n would be expanded to \n(sum(node_memory_MemTotal{job=\"my-service\"}) - sum(node_memory_MemFree{job=\"my-service\"} + node_memory_Buffers{job=\"my-service\"} + node_memory_Cached{job=\"my-service\"})) / sum(node_memory_MemTotal{job=\"my-service\"}) < 0.4\n.\n\n\n\n\n\n\n@replicas_running\n\n\nWhether the number of running replicas is as desired.\nRequirements:\n \ncAdvisor\n metrics and a service running in the replicated mode. The alert uses \ncontainer_memory_usage_bytes\n metric only as a way to count the number of running containers.\nExample:\n \n@replicas_running\n for a service with the number of desired replicas set to \n3\n would be expanded to \ncount(container_memory_usage_bytes{container_label_com_docker_swarm_service_name=\"my-service\"}) != 3\n.\n\n\n\n\n\n\n@replicas_more_than\n\n\nWhether the number of running replicas is more than desired.\nRequirements:\n \ncAdvisor\n metrics and a service running in the replicated mode. The alert uses \ncontainer_memory_usage_bytes\n metric only as a way to count the number of running containers.\nExample:\n \n@replicas_running\n for a service with the number of desired replicas set to \n3\n would be expanded to \ncount(container_memory_usage_bytes{container_label_com_docker_swarm_service_name=\"my-service\"}) > 3\n.\n\n\n\n\n\n\n@replicas_less_than\n\n\nWhether the number of running replicas is less than desired.\nRequirements:\n \ncAdvisor\n metrics and a service running in the replicated mode. The alert uses \ncontainer_memory_usage_bytes\n metric only as a way to count the number of running containers.\nExample:\n \n@replicas_running\n for a service with the number of desired replicas set to \n3\n would be expanded to \ncount(container_memory_usage_bytes{container_label_com_docker_swarm_service_name=\"my-service\"}) < 3\n.\n\n\n\n\n\n\n@resp_time_above:[QUANTILE],[RATE_DURATION],[PERCENTAGE]\n\n\nWhether response time of a given \nquantile\n over the specified \nrate duration\n is above the set \npercentage\n.\nRequirements:\n histogram with the name \nhttp_server_resp_time\n and with response times expessed in seconds.\n[QUANTILE] must be one of the quantiles defined in the metric.\n[RATE_DURATION] can be in any format supported by Prometheus (e.g. \n5m\n).\n[PERCENTAGE] must be specified as a decimal value (e.g. \n0.8\n equals \n80%\n).\nExample:\n \n@resp_time_above:0.1,5m,0.9999\n would be expanded to \nsum(rate(http_server_resp_time_bucket{job=\"my-service\", le=\"0.1\"}[5m])) / sum(rate(http_server_resp_time_count{job=\"my-service\"}[5m])) < 0.9999\n.\n\n\n\n\n\n\n@resp_time_below:[QUANTILE],[RATE_DURATION],[PERCENTAGE]\n\n\nWhether response time of a given \nquantile\n over the specified \nrate duration\n is below the set \npercentage\n.\nRequirements:\n histogram with the name \nhttp_server_resp_time\n and with response times expessed in seconds.\n[QUANTILE] must be one of the quantiles defined in the metric.\n[RATE_DURATION] can be in any format supported by Prometheus (e.g. \n5m\n).\n[PERCENTAGE] must be specified as a decimal value (e.g. \n0.8\n equals \n80%\n).\nExample:\n \n@resp_time_below:0.025,5m,0.75\n would be expanded to \nsum(rate(http_server_resp_time_bucket{job=\"my-service\", le=\"0.025\"}[5m])) / sum(rate(http_server_resp_time_count{job=\"my-service\"}[5m])) > 0.75\n.\n\n\n\n\n\n\n@resp_time_server_error:[RATE_DURATION],[PERCENTAGE]\n\n\nWhether error rate over the specified \nrate duration\n is below the set \npercentage\n.\nRequirements:\n histogram with the name \nhttp_server_resp_time\n and with label \ncode\n set to value of the HTTP response code.\n[RATE_DURATION] can be in any format supported by Prometheus (e.g. \n5m\n).\n[PERCENTAGE] must be specified as a decimal value (e.g. \n0.8\n equals \n80%\n).\nExample:\n \n@resp_time_server_error:5m,0.001\n would be expanded to \nsum(rate(http_server_resp_time_count{job=\"my-service\", code=~\"^5..$$\"}[5m])) / sum(rate(http_server_resp_time_count{job=\"my-service\"}[5m])) > 0.001\n.\n\n\n\n\n\n\n@service_mem_limit:[PERCENTAGE]\n\n\nWhether service memory usage is over specified percentage of the service memory limit.\nRequirements:\n \ncAdvisor\n metrics and service memory limit specified as service resource.\n[PERCENTAGE] must be specified as a decimal value (e.g. \n0.8\n equals \n80%\n).\nExample:\n If \nserviceName\n is set to \nmy-service\n, \n@service_mem_limit:0.8\n would be expanded to \ncontainer_memory_usage_bytes{container_label_com_docker_swarm_service_name=\"my-service\"}/container_spec_memory_limit_bytes{container_label_com_docker_swarm_service_name=\"my-service\"} > 0.8\n.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nI hope that the number of shortcuts will grow with time thanks to community contributions. Please create \nan issue\n with the \nalertIf\n statement and the suggested shortcut and I'll add it to the code as soon as possible.\n\n\n\n\nAlertIf Secrets Configuration\n\u00b6\n\n\nDocker Flow Monitor\n supports \nDocker Secrets\n for adding custom alertIf shortcuts. Only secrets with names that start with \nalertif-\n or \nalertif_\n will be considered. \nalertIf\n shortcuts are configured as a yaml file with a series of dictionaries. The key of each dictionary is your custom \nalertIf\n shortcut which must begin with the \n@\n character. The value of each dictionary consist of three keys: \nexpanded\n, \nannotations\n and \nlabels\n. \nexpanded\n contains the expanded alert using go \ntemplates\n. \nannotations\n and \nlabels\n contains a dictionary with the alert's annotations and labels. For example \n@service_mem_limit\n is defined by the following yaml:\n\n\n\"@service_mem_limit\"\n:\n\n  \nexpanded\n:\n \ncontainer_memory_usage_bytes{container_label_com_docker_swarm_service_name=\"{{ .Alert.ServiceName }}\"}/container_spec_memory_limit_bytes{container_label_com_docker_swarm_service_name=\"{{ .Alert.ServiceName }}\"} > {{ index .Values 0 }}\n\n  \nannotations\n:\n\n    \nsummary\n:\n \nMemory of the service {{ .Alert.ServiceName }} is over {{ index .Values 0 }}\n\n  \nlabels\n:\n\n    \nreceiver\n:\n \nsystem\n\n    \nservice\n:\n \n\"{{\n \n.Alert.ServiceName\n \n}}\"\n\n\n\n\n\n\n\nTip\n\n\nAlertIf shortcuts defined in secrets will take priority over default shortcuts.\n\n\n\n\nAlertIf Logical Operators\n\u00b6\n\n\nThe logical operators \nand\n, \nunless\n, and \nor\n can be used in combinations with AlertIf Parameter Shortcuts. For example, to create an alert that triggers when response time is low unless response time is high, set \nalertIf=@resp_time_below:0.025,5m,0.75_unless_@resp_time_above:0.1,5m,0.99\n. This alert prevents \n@resp_time_below\n from triggering while \n@resp_time_above\n is triggering. The \nsummary\n annotation for this alert will be merged with the \nand\n operator: \"Response time of the service my-service is below 0.025 unless Response time of the service my-service is above 0.1\". When using logical operators, there are no default alert labels. The alert labels will have to be manually set by using the \nalertLabels\n query parameter.\n\n\nMore information on the logical operators can be found on Prometheus's querying \ndocumentation\n.\n\n\nRemove\n\u00b6\n\n\n\n\nTip\n\n\nRemoves Prometheus scrapes and alerts\n\n\n\n\nRemove\n endpoint can be used to send request to \nDocker Flow Monitor\n with the goal of removing scrapes and alerts related to a service.\n\n\nQuery parameters that follow should be added to the base address \n[MONITOR_IP]:[MONITOR_PORT]/v1/docker-flow-monitor/remove\n.\n\n\n\n\n\n\n\n\nQuery\n\n\nDescription\n\n\nRequired\n\n\n\n\n\n\n\n\n\n\nserviceName\n\n\nThe name of the service that should be removed.\n\n\nYes",
            "title": "Usage"
        },
        {
            "location": "/usage/#usage",
            "text": "Docker Flow Monitor  can be controlled by sending HTTP requests or through Docker Service labels when combined with  Docker Flow Swarm Listener .",
            "title": "Usage"
        },
        {
            "location": "/usage/#reconfigure",
            "text": "Reconfigure  endpoint can be used to send requests to  Docker Flow Monitor  with the goal of adding or modifying existing scrape targets and alerts. Parameters are divided into  scrape  and  alert  groups.  Query parameters that follow should be added to the base address  [MONITOR_IP]:[MONITOR_PORT]/v1/docker-flow-monitor/reconfigure .",
            "title": "Reconfigure"
        },
        {
            "location": "/usage/#scrape-parameters",
            "text": "Tip  Defines Prometheus scrape targets      Query  Description  Required      metricsPath  The path of the metrics endpoint. Defaults to  /metrics .  No    scrapeInterval  How frequently to scrape targets from this job.  No    scrapeTimeout  Per-scrape timeout when scraping this job.  No    scrapePort  The port through which metrics are exposed.  Yes    serviceName  The name of the service that exports metrics.  Yes    scrapeType  A set of targets and parameters describing how to scrape metrics.  No     You can find more about scrapeType's on  Scrape Config .",
            "title": "Scrape Parameters"
        },
        {
            "location": "/usage/#alert-parameters",
            "text": "Tip  Defines Prometheus alerts      Query  Description  Required      alertAnnotations  This parameter is translated to Prometheus alert  ANNOTATIONS  statement. Annotations are used to store longer additional information. Example:   summary=Service memory is high,description=Do something or start panicking  No    alertFor  This parameter is translated to Prometheus alert  FOR  statement. It causes Prometheus to wait for a certain duration between first encountering a new expression output vector element (like an instance with a high HTTP error rate) and counting an alert as firing for this element. Elements that are active, but not firing yet, are in pending state. This parameter expects a number with time suffix (e.g.  s  for seconds,  m  for minutes). Example:   30s  No    alertIf  This parameter is translated to Prometheus alert  IF  statement. It is an expression that will be evaluated and, if it returns  true , an alert will be fired. Example:  container_memory_usage_bytes{container_label_com_docker_swarm_service_name=\"go-demo\"}/container_spec_memory_limit_bytes{container_label_com_docker_swarm_service_name=\"go-demo\"} > 0.8  Yes    alertLabels  This parameter is translated to Prometheus alert  LABELS  statement. It allows specifying a set of additional labels to be attached to the alert. Multiple labels can be separated with comma ( , ). Example:   severity=high,receiver=system  No    alertName  The name of the alert. It is combined with the  serviceName  thus producing an unique identifier. Example:   memoryAlert  Yes    serviceName  The name of the service. It is combined with the  alertName  thus producing an unique identifier. Example:   go-demo  Yes    alertPersistent  When set to  true , the alert will persist when the service is scaled to zero replicas. Example:   true  No     Those parameters can be indexed so that multiple alerts can be defined for a service. Indexing is sequential and starts from 1. An example of indexed  alertName  could be  alertName.1=memload  and  alertName.2=diskload .  Please visit  Alerting Overview  for more information about the rules for defining Prometheus alerts.",
            "title": "Alert Parameters"
        },
        {
            "location": "/usage/#alertif-parameter-shortcuts",
            "text": "Tip  Allows short specification of commonly used  alertIf  parameters      Shortcut  Description      @node_fs_limit:[PERCENTAGE]  Whether node file system usage is over specified percentage of the total available file system size. Requirements:   node-exporter  metrics [PERCENTAGE] must be specified as a decimal value (e.g.  0.8  equals  80% ). Example:   @node_fs_limit:0.8  would be expanded to  (node_filesystem_size{fstype=\"aufs\", job=\"my-service\"} - node_filesystem_free{fstype=\"aufs\", job=\"my-service\"}) / node_filesystem_size{fstype=\"aufs\", job=\"my-service\"} > 0.8 .    @node_mem_limit:[PERCENTAGE]  Whether node memory usage is over specified percentage of the total node memory. Requirements:   node-exporter  metrics [PERCENTAGE] must be specified as a decimal value (e.g.  0.8  equals  80% ). Example:   @node_mem_limit:0.8  would be expanded to  (sum by (instance) (node_memory_MemTotal{job=\"my-service\"}) - sum by (instance) (node_memory_MemFree{job=\"my-service\"} + node_memory_Buffers{job=\"my-service\"} + node_memory_Cached{job=\"my-service\"})) / sum by (instance) (node_memory_MemTotal{job=\"my-service\"}) > 0.8 .    @node_mem_limit_total_above:[PERCENTAGE]  Whether memory usage of all the nodes is over the specified percentage of the total memory. Requirements:   node-exporter  metrics [PERCENTAGE] must be specified as a decimal value (e.g.  0.8  equals  80% ). Example:   @node_mem_limit_total_above:0.8  would be expanded to  (sum(node_memory_MemTotal{job=\"my-service\"}) - sum(node_memory_MemFree{job=\"my-service\"} + node_memory_Buffers{job=\"my-service\"} + node_memory_Cached{job=\"my-service\"})) / sum(node_memory_MemTotal{job=\"my-service\"}) > 0.8 .    @node_mem_limit_total_below:[PERCENTAGE]  Whether memory usage of all the nodes is below the specified percentage of the total memory. Requirements:   node-exporter  metrics [PERCENTAGE] must be specified as a decimal value (e.g.  0.8  equals  80% ). Example:   @node_mem_limit_total_below:0.4  would be expanded to  (sum(node_memory_MemTotal{job=\"my-service\"}) - sum(node_memory_MemFree{job=\"my-service\"} + node_memory_Buffers{job=\"my-service\"} + node_memory_Cached{job=\"my-service\"})) / sum(node_memory_MemTotal{job=\"my-service\"}) < 0.4 .    @replicas_running  Whether the number of running replicas is as desired. Requirements:   cAdvisor  metrics and a service running in the replicated mode. The alert uses  container_memory_usage_bytes  metric only as a way to count the number of running containers. Example:   @replicas_running  for a service with the number of desired replicas set to  3  would be expanded to  count(container_memory_usage_bytes{container_label_com_docker_swarm_service_name=\"my-service\"}) != 3 .    @replicas_more_than  Whether the number of running replicas is more than desired. Requirements:   cAdvisor  metrics and a service running in the replicated mode. The alert uses  container_memory_usage_bytes  metric only as a way to count the number of running containers. Example:   @replicas_running  for a service with the number of desired replicas set to  3  would be expanded to  count(container_memory_usage_bytes{container_label_com_docker_swarm_service_name=\"my-service\"}) > 3 .    @replicas_less_than  Whether the number of running replicas is less than desired. Requirements:   cAdvisor  metrics and a service running in the replicated mode. The alert uses  container_memory_usage_bytes  metric only as a way to count the number of running containers. Example:   @replicas_running  for a service with the number of desired replicas set to  3  would be expanded to  count(container_memory_usage_bytes{container_label_com_docker_swarm_service_name=\"my-service\"}) < 3 .    @resp_time_above:[QUANTILE],[RATE_DURATION],[PERCENTAGE]  Whether response time of a given  quantile  over the specified  rate duration  is above the set  percentage . Requirements:  histogram with the name  http_server_resp_time  and with response times expessed in seconds. [QUANTILE] must be one of the quantiles defined in the metric. [RATE_DURATION] can be in any format supported by Prometheus (e.g.  5m ). [PERCENTAGE] must be specified as a decimal value (e.g.  0.8  equals  80% ). Example:   @resp_time_above:0.1,5m,0.9999  would be expanded to  sum(rate(http_server_resp_time_bucket{job=\"my-service\", le=\"0.1\"}[5m])) / sum(rate(http_server_resp_time_count{job=\"my-service\"}[5m])) < 0.9999 .    @resp_time_below:[QUANTILE],[RATE_DURATION],[PERCENTAGE]  Whether response time of a given  quantile  over the specified  rate duration  is below the set  percentage . Requirements:  histogram with the name  http_server_resp_time  and with response times expessed in seconds. [QUANTILE] must be one of the quantiles defined in the metric. [RATE_DURATION] can be in any format supported by Prometheus (e.g.  5m ). [PERCENTAGE] must be specified as a decimal value (e.g.  0.8  equals  80% ). Example:   @resp_time_below:0.025,5m,0.75  would be expanded to  sum(rate(http_server_resp_time_bucket{job=\"my-service\", le=\"0.025\"}[5m])) / sum(rate(http_server_resp_time_count{job=\"my-service\"}[5m])) > 0.75 .    @resp_time_server_error:[RATE_DURATION],[PERCENTAGE]  Whether error rate over the specified  rate duration  is below the set  percentage . Requirements:  histogram with the name  http_server_resp_time  and with label  code  set to value of the HTTP response code. [RATE_DURATION] can be in any format supported by Prometheus (e.g.  5m ). [PERCENTAGE] must be specified as a decimal value (e.g.  0.8  equals  80% ). Example:   @resp_time_server_error:5m,0.001  would be expanded to  sum(rate(http_server_resp_time_count{job=\"my-service\", code=~\"^5..$$\"}[5m])) / sum(rate(http_server_resp_time_count{job=\"my-service\"}[5m])) > 0.001 .    @service_mem_limit:[PERCENTAGE]  Whether service memory usage is over specified percentage of the service memory limit. Requirements:   cAdvisor  metrics and service memory limit specified as service resource. [PERCENTAGE] must be specified as a decimal value (e.g.  0.8  equals  80% ). Example:  If  serviceName  is set to  my-service ,  @service_mem_limit:0.8  would be expanded to  container_memory_usage_bytes{container_label_com_docker_swarm_service_name=\"my-service\"}/container_spec_memory_limit_bytes{container_label_com_docker_swarm_service_name=\"my-service\"} > 0.8 .      Note  I hope that the number of shortcuts will grow with time thanks to community contributions. Please create  an issue  with the  alertIf  statement and the suggested shortcut and I'll add it to the code as soon as possible.",
            "title": "AlertIf Parameter Shortcuts"
        },
        {
            "location": "/usage/#alertif-secrets-configuration",
            "text": "Docker Flow Monitor  supports  Docker Secrets  for adding custom alertIf shortcuts. Only secrets with names that start with  alertif-  or  alertif_  will be considered.  alertIf  shortcuts are configured as a yaml file with a series of dictionaries. The key of each dictionary is your custom  alertIf  shortcut which must begin with the  @  character. The value of each dictionary consist of three keys:  expanded ,  annotations  and  labels .  expanded  contains the expanded alert using go  templates .  annotations  and  labels  contains a dictionary with the alert's annotations and labels. For example  @service_mem_limit  is defined by the following yaml:  \"@service_mem_limit\" : \n   expanded :   container_memory_usage_bytes{container_label_com_docker_swarm_service_name=\"{{ .Alert.ServiceName }}\"}/container_spec_memory_limit_bytes{container_label_com_docker_swarm_service_name=\"{{ .Alert.ServiceName }}\"} > {{ index .Values 0 }} \n   annotations : \n     summary :   Memory of the service {{ .Alert.ServiceName }} is over {{ index .Values 0 }} \n   labels : \n     receiver :   system \n     service :   \"{{   .Alert.ServiceName   }}\"    Tip  AlertIf shortcuts defined in secrets will take priority over default shortcuts.",
            "title": "AlertIf Secrets Configuration"
        },
        {
            "location": "/usage/#alertif-logical-operators",
            "text": "The logical operators  and ,  unless , and  or  can be used in combinations with AlertIf Parameter Shortcuts. For example, to create an alert that triggers when response time is low unless response time is high, set  alertIf=@resp_time_below:0.025,5m,0.75_unless_@resp_time_above:0.1,5m,0.99 . This alert prevents  @resp_time_below  from triggering while  @resp_time_above  is triggering. The  summary  annotation for this alert will be merged with the  and  operator: \"Response time of the service my-service is below 0.025 unless Response time of the service my-service is above 0.1\". When using logical operators, there are no default alert labels. The alert labels will have to be manually set by using the  alertLabels  query parameter.  More information on the logical operators can be found on Prometheus's querying  documentation .",
            "title": "AlertIf Logical Operators"
        },
        {
            "location": "/usage/#remove",
            "text": "Tip  Removes Prometheus scrapes and alerts   Remove  endpoint can be used to send request to  Docker Flow Monitor  with the goal of removing scrapes and alerts related to a service.  Query parameters that follow should be added to the base address  [MONITOR_IP]:[MONITOR_PORT]/v1/docker-flow-monitor/remove .     Query  Description  Required      serviceName  The name of the service that should be removed.  Yes",
            "title": "Remove"
        },
        {
            "location": "/migration/",
            "text": "Migration Guide\n\u00b6\n\n\nDocker Flow Monitor\n (DFM) now supports Prometheus 2! Prometheus 2 includes a new storage subsystem that has reduce CPU usage and lower disk space usage compared to Prometheus 1.  This guide highlights issues that you may encounter when upgrading to Prometheus 2.\n\n\nDatabase\n\u00b6\n\n\nWhen upgrading from DFM backed by Prometheus 1 to Prometheus 2, DFM will create a new database supported by Prometheus 2. If you need to access the previous data scraped by Prometheus 1, downgrade your DFM instance using tag: \n17.12.12-36\n. DFM will launch with Prometheus 1, and continue using the previous database.\n\n\nBackwards Compatibility\n\u00b6\n\n\nThe command line arguments for Prometheus 2 has changed. This is detailed in Prometheus's \nOfficial Migration Guide\n. \nDFM\n will continue to support the previous command line arguments prefixed by \nARG_\n:\n\n\n\n\nSetting \nARG_ALERTMANAGER_URL\n configures the alertmanager correctly for Prometheus 2.\n\n\nARG_STORAGE_LOCAL_PATH\n maps to \n--storage.tsdb.path\n.\n\n\nARG_STORAGE_LOCAL_RETENTION\n maps to \n--storage.tsdb.retention\n.\n\n\nARG_QUERY_STALENESS-DELTA\n maps to \n--query.lookback-delta\n.\n\n\nSetting \nARG_ENABLE-REMOTE-SHUTDOWN=true\n sets flag \n--web.enable-lifecycle\n\n\n\n\nYou can explore the new flags in Prometheus 2 by downloading the binary from their \nDownload Page\n and running \n./prometheus -h\n.",
            "title": "Migration Guide"
        },
        {
            "location": "/migration/#migration-guide",
            "text": "Docker Flow Monitor  (DFM) now supports Prometheus 2! Prometheus 2 includes a new storage subsystem that has reduce CPU usage and lower disk space usage compared to Prometheus 1.  This guide highlights issues that you may encounter when upgrading to Prometheus 2.",
            "title": "Migration Guide"
        },
        {
            "location": "/migration/#database",
            "text": "When upgrading from DFM backed by Prometheus 1 to Prometheus 2, DFM will create a new database supported by Prometheus 2. If you need to access the previous data scraped by Prometheus 1, downgrade your DFM instance using tag:  17.12.12-36 . DFM will launch with Prometheus 1, and continue using the previous database.",
            "title": "Database"
        },
        {
            "location": "/migration/#backwards-compatibility",
            "text": "The command line arguments for Prometheus 2 has changed. This is detailed in Prometheus's  Official Migration Guide .  DFM  will continue to support the previous command line arguments prefixed by  ARG_ :   Setting  ARG_ALERTMANAGER_URL  configures the alertmanager correctly for Prometheus 2.  ARG_STORAGE_LOCAL_PATH  maps to  --storage.tsdb.path .  ARG_STORAGE_LOCAL_RETENTION  maps to  --storage.tsdb.retention .  ARG_QUERY_STALENESS-DELTA  maps to  --query.lookback-delta .  Setting  ARG_ENABLE-REMOTE-SHUTDOWN=true  sets flag  --web.enable-lifecycle   You can explore the new flags in Prometheus 2 by downloading the binary from their  Download Page  and running  ./prometheus -h .",
            "title": "Backwards Compatibility"
        },
        {
            "location": "/release-notes/",
            "text": "Release Notes\n\u00b6\n\n\nPlease visit \nproject releases\n.",
            "title": "Release Notes"
        },
        {
            "location": "/release-notes/#release-notes",
            "text": "Please visit  project releases .",
            "title": "Release Notes"
        },
        {
            "location": "/license/",
            "text": "Docker Flow Proxy License (MIT)\n\u00b6\n\n\nCopyright \u00a9 2017 Viktor Farcic\n\n\nThe MIT License (MIT)\n\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.",
            "title": "License"
        },
        {
            "location": "/license/#docker-flow-proxy-license-mit",
            "text": "Copyright \u00a9 2017 Viktor Farcic  The MIT License (MIT)  Permission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:  The above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.",
            "title": "Docker Flow Proxy License (MIT)"
        }
    ]
}